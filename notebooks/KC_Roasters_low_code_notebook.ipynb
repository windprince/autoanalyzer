{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EaJ8AGwpM-2"
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPPJ7VeM13-K"
   },
   "source": [
    "\n",
    "### Business Context\n",
    "\n",
    "Coffee roasting is the process of turning green coffee beans into brown ones. Brown coffee beans can be made in a variety of methods, which also influences the flavor of the end product. A roasting instrument is basically a convection oven. It is a mechanism of inflicting heat energy into the raw product which makes the product consumable.\n",
    "And the price of coffee is heavily influenced by the quality of the beans after roasting. As a result, the cost can be determined depending on the quality of the beans after roasting.\n",
    "\n",
    "The rising automation in the manufacturing business necessitates the automation of quality inspection of output products with minimal human intervention. Quality inspectors in businesses examine product quality after it is manufactured to ensure that it meets industry standards. \n",
    "\n",
    "Each product's quality inspection is a time-consuming manual process, and a low-quality product wastes upstream factory capacity, consumables, labor, and money. With the emerging AI trend, companies are looking to leverage machine learning-based technologies to automate material quality inspection during the manufacturing process to reduce human intervention while achieving human-level or better accuracy.\n",
    "\n",
    "\n",
    "\n",
    "### Objective\n",
    "\n",
    "A roasting corporation named \"KC Roasters\" has engaged you to predict the quality of a roasting instrument's outputs, which will be used to determine the price of coffee beans.\n",
    "The quality value ranges from 0 to 100 with 0 being the worst and 100 being the best.\n",
    "and the higher the quality of the beans, the higher the price.\n",
    "\n",
    "The coffee roasting instrument used by Roasters is divided into five equal-sized compartments, each with three temperature sensors. 3 sensors have been installed at 3 different locations to be able to capture temperature at different locations inside the chamber.\n",
    "Additionally, the height of raw material (volume entering the chamber) and relative humidity of roasted material is provided\n",
    "\n",
    "The data shared consists of 17 predictor variables and a continuous target variable, and the aim is to build a Regression model which can accurately predict the quality of the product. After finding out the quality, the company can decide the cost of beans effectively.\n",
    "\n",
    "\n",
    "### Data Dictionary\n",
    "- T_data_1_1 - Temperature recorded by 1st sensor in the 1st chamber in Fahrenheit\n",
    "- T_data_1_2 - Temperature recorded by 2nd sensor in the 1st chamber in Fahrenheit\n",
    "- T_data_1_3 - Temperature recorded by 3rd sensor in the 1st chamber in Fahrenheit\n",
    "- T_data_2_1 - Temperature recorded by 1st sensor in the 2nd chamber in Fahrenheit\n",
    "- T_data_2_2 - Temperature recorded by 2nd sensor in the 2nd chamber in Fahrenheit\n",
    "- T_data_2_3 - Temperature recorded by 3rd sensor in the 2nd chamber in Fahrenheit\n",
    "- T_data_3_1 - Temperature recorded by 1st sensor in the 3rd chamber in Fahrenheit\n",
    "- T_data_3_2 - Temperature recorded by 2nd sensor in the 3rd chamber in Fahrenheit\n",
    "- T_data_3_3 - Temperature recorded by 3rd sensor in the 3rd chamber in Fahrenheit\n",
    "- T_data_4_1 - Temperature recorded by 1st sensor in the 4th chamber in Fahrenheit\n",
    "- T_data_4_2 - Temperature recorded by 2nd sensor in the 4th chamber in Fahrenheit\n",
    "- T_data_4_3 - Temperature recorded by 3rd sensor in the 4th chamber in Fahrenheit\n",
    "- T_data_5_1 - Temperature recorded by 1st sensor in the 5th chamber in Fahrenheit\n",
    "- T_data_5_2 - Temperature recorded by 2nd sensor in the 5th chamber in Fahrenheit\n",
    "- T_data_5_3 - Temperature recorded by 3rd sensor in the 5th chamber in Fahrenheit\n",
    "- H_data - Height of Raw material layer, basically represents the volume of raw material going inside the chamber in pounds.\n",
    "- AH_data - Roasted Coffee beans relative humidity.\n",
    "- quality - Quality of the beans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xX1NYQ2zlou"
   },
   "source": [
    "### **Please read the instructions carefully before starting the project.** \n",
    "This is a commented Jupyter IPython Notebook file in which all the instructions and tasks to be performed are mentioned. \n",
    "* Blanks '_______' are provided in the notebook that \n",
    "needs to be filled with an appropriate code to get the correct result. With every '_______' blank, there is a comment that briefly describes what needs to be filled in the blank space. \n",
    "* Identify the task to be performed correctly, and only then proceed to write the required code.\n",
    "* Fill the code wherever asked by the commented lines like \"# write your code here\" or \"# complete the code\". Running incomplete code may throw error.\n",
    "* Please run the codes in a sequential manner from the beginning to avoid any unnecessary errors.\n",
    "* Add the results/observations (wherever mentioned) derived from the analysis in the presentation and submit the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85dWBGXv_L6k"
   },
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas==1.5.3 numpy==1.25.2 matplotlib==3.7.1 seaborn==0.13.1 scikit-learn==1.2.2 xgboost==2.0.3 -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: After running the above cell, kindly restart the notebook kernel and run all cells sequentially from the start again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xr1BvkK-_L6k",
    "outputId": "dca7fb1b-f691-4ece-c411-96134fd10673"
   },
   "outputs": [],
   "source": [
    "# Libraries to help with reading and manipulating data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Libaries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To tune model, get different metric scores, and split data\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "# To be used for data scaling and one hot encoding\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# To impute missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# To do hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# To be used for creating pipelines and personalizing them\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# To define maximum number of columns to be displayed in a dataframe\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# To supress scientific notations for a dataframe\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "\n",
    "# To help with model building\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (\n",
    "    BaggingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    AdaBoostRegressor,\n",
    "    StackingRegressor,\n",
    ")\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "# To suppress scientific notations\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "\n",
    "# To suppress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxhpZv9y-qTw"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_BQHHoFz7tm"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('_______') ##  Complete the code to read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxzULAqM2L5x"
   },
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-5jUOgu-qTz"
   },
   "source": [
    "The initial steps to get an overview of any dataset is to: \n",
    "- observe the first few rows of the dataset, to check whether the dataset has been loaded properly or not\n",
    "- get information about the number of rows and columns in the dataset\n",
    "- find out the data types of the columns to ensure that data is stored in the preferred format and the value of each property is as expected.\n",
    "- check the statistical summary of the dataset to get an overview of the numerical columns of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQi5ygTC-qT1"
   },
   "source": [
    "### Checking the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HthnUm5yz6tp"
   },
   "outputs": [],
   "source": [
    "# Checking the number of rows and columns in the training data\n",
    "data.'_______' ##  Complete the code to view dimensions of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlzqMR1K-qTz"
   },
   "source": [
    "### Displaying the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lckuach_HhTw"
   },
   "outputs": [],
   "source": [
    "# let's view the top 5 rows of the data\n",
    "data.'_______' ##  Complete the code to view top 5 rows of the data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdn3Dug8EpJb"
   },
   "outputs": [],
   "source": [
    "# let's view the last 5 rows of the data\n",
    "data.'_______' ##  Complete the code to view last 5 rows of the data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNr4bWoM-qT5"
   },
   "source": [
    "### Checking for duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LoZAdca6E2R3"
   },
   "outputs": [],
   "source": [
    "# let's check for duplicate values in the data\n",
    "data.'_______' ##  Complete the code to check duplicate entries in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ch_TjRfF-qT5"
   },
   "source": [
    "### Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6i5Sj6VRE57b"
   },
   "outputs": [],
   "source": [
    "# let's check for missing values in the data\n",
    "data.'_______' ##  Complete the code to check missing entries in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TcqcxbK-qT3"
   },
   "source": [
    "### Checking the data types of the columns for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLGFkKPUEtrk"
   },
   "outputs": [],
   "source": [
    "# let's check the data types of the columns in the dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GccCfv9MbmS2"
   },
   "source": [
    "### Statistical summary of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ou8hylGmFCSe"
   },
   "outputs": [],
   "source": [
    "# let's view the statistical summary of the numerical columns in the data\n",
    "data.'_______' ##  Complete the code to print the statitical summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pcCtP0pW22Ia"
   },
   "outputs": [],
   "source": [
    "#ceating the copy of the dataframe\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhPuzWO7hmV8"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZ4AX18Z27oi"
   },
   "source": [
    "### Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ozzmq7dm_L6s"
   },
   "outputs": [],
   "source": [
    "# function to plot a boxplot and a histogram along the same scale.\n",
    "\n",
    "\n",
    "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (12,7))\n",
    "    kde: whether to the show density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows=2,  # Number of rows of the subplot grid= 2\n",
    "        sharex=True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize=figsize,\n",
    "    )  # creating the 2 subplots\n",
    "    sns.boxplot(\n",
    "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
    "    )  # boxplot will be created and a triangle will indicate the mean value of the column\n",
    "    sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
    "    ) if bins else sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
    "    )  # For histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
    "    )  # Add mean to the histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
    "    )  # Add median to the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AXITHmedFlgV"
   },
   "outputs": [],
   "source": [
    "# Observations on T_data_1_1\n",
    "histogram_boxplot(df, \"T_data_1_1\", figsize=(12, 7), kde=False, bins=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hecV4OaaFsRt"
   },
   "outputs": [],
   "source": [
    "histogram_boxplot(df, \"________\", figsize=(12, 7), kde=False, bins=None) #  Complete the code to view for T_data_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81vVDHgcFv6O"
   },
   "outputs": [],
   "source": [
    "histogram_boxplot(df, \"________\", figsize=(12, 7), kde=False, bins=None) #  Complete the code to view for T_data_1_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zic6pUjrIBbM"
   },
   "outputs": [],
   "source": [
    "# minimum value for 2nd sensor is 168 and 183 for 3rd sensor, so we will replace values less than 168 in first sensor with 168\n",
    "df[\"T_data_1_1\"].clip(lower=168, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poGeDseUIGWw"
   },
   "outputs": [],
   "source": [
    "histogram_boxplot(df, \"________\", figsize=(12, 7), kde=False, bins=None) #  Complete the code to view for T_data_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXeRJ6SbII_h"
   },
   "outputs": [],
   "source": [
    "#  Complete the code to view for T_data_2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPktBP0aIMhT"
   },
   "outputs": [],
   "source": [
    "#  Complete the code to view for T_data_2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAd_4HmSIPiN"
   },
   "outputs": [],
   "source": [
    "df[\"T_data_2_1\"].clip(lower=107, inplace=True) # Check for minimum value for 2nd sensor and for 3rd sensor and replace values less than in first sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rltt8hPbvAvb"
   },
   "outputs": [],
   "source": [
    "#  Write the code to view for for each senosrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iH_2G6R9JDSz"
   },
   "outputs": [],
   "source": [
    "histogram_boxplot(df, \"________\", figsize=(12, 7), kde=False, bins=None) #  Complete the code to view for quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0myHS43S_L7G"
   },
   "source": [
    "### Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGghInazJyZW"
   },
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (16, 10)})\n",
    "sns.heatmap(\n",
    "    df.corr(), annot=True, linewidths=0.5, center=0, cbar=False, cmap=\"Spectral\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3RUwPXdJVIp"
   },
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (8, 4)})\n",
    "\n",
    "# Quality vs AH_data\n",
    "sns.scatterplot(data=df, x=\"quality\", y=\"AH_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_vmDAO7JYPO"
   },
   "outputs": [],
   "source": [
    "# Quality vs H_data\n",
    "sns.scatterplot(data=df, x=\"quality\", y=\"H_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgwxhpN4Jcka"
   },
   "outputs": [],
   "source": [
    "# quality vs temp in 1st chamber\n",
    "\n",
    "fig = plt.figure(figsize = (20,15))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 1)\n",
    "sns.scatterplot(data=df, x=\"quality\", y=\"_______\")  #  Complete the code to view for T_data_1_1\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 2)\n",
    "sns.scatterplot(data=df, x=\"quality\", y=\"______\")  #  Complete the code to view for T_data_1_2\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 3) \n",
    "sns.scatterplot(data=df, x=\"quality\", y=\"_____\")   #  Complete the code to view for T_data_1_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qNL3RxZ8JjNm"
   },
   "outputs": [],
   "source": [
    "# Write the code for quality vs temp in each chamber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bp8vC9MZbp09"
   },
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AeKseH4_J9Fe"
   },
   "outputs": [],
   "source": [
    "# let's create a copy of the data\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRTo44MMKH6_"
   },
   "outputs": [],
   "source": [
    "# Dividing data into X and y\n",
    "X = df1.drop([\"quality\"], axis=1)\n",
    "y = df1[\"quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMcXqTn8Koun"
   },
   "outputs": [],
   "source": [
    "# Splitting data into training and validation set:\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split('_______') ## Complete the code to split the data into train test in the ratio 60:40\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split('_______') ## Complete the code to split the data into train test in the ratio 50:50\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrxi3_UI_L7R"
   },
   "source": [
    "### Missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehVxymYKKtNV"
   },
   "outputs": [],
   "source": [
    "# creating an instace of the imputer to be used\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DEmapTOsK5Lr"
   },
   "outputs": [],
   "source": [
    "# Fit and transform the train data\n",
    "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "\n",
    "# Transform the validation data\n",
    "X_val =  '_______' ## Complete the code to impute missing values in X_val\n",
    "\n",
    "# Transform the test data\n",
    "X_test = '_______' ## Complete the code to impute missing values in X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdBYb9dWK3Rk"
   },
   "outputs": [],
   "source": [
    "# Checking that no column has missing values in train or test sets\n",
    "print(X_train.isna().sum())\n",
    "print(\"-\" * 30)\n",
    "\n",
    "X_val.'_______' ## Complete the code to check the count of missing values in validation set\n",
    "X_test.'_______' ## Complete the code to check the count of missing values in test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtM-OZGaK_9R"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIKB264q_L7T"
   },
   "source": [
    "**Let's create a function to calculate different metrics, so that we don't have to use the same code repeatedly for each model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJe-BS-1LFG7"
   },
   "outputs": [],
   "source": [
    "# function to compute adjusted R-squared\n",
    "def adj_r2_score(predictors, targets, predictions):\n",
    "    r2 = r2_score(targets, predictions)\n",
    "    n = predictors.shape[0]\n",
    "    k = predictors.shape[1]\n",
    "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "\n",
    "# function to compute different metrics to check performance of a regression model\n",
    "def model_performance_regression(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check regression model performance\n",
    "\n",
    "    model: regressor\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "\n",
    "    # predicting using the independent variables\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    r2 = r2_score(target, pred)  # to compute R-squared\n",
    "    adjr2 = adj_r2_score(predictors, target, pred)  # to compute adjusted R-squared\n",
    "    rmse = np.sqrt(mean_squared_error(target, pred))  # to compute RMSE\n",
    "    mae = mean_absolute_error(target, pred)  # to compute MAE\n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R-squared\": r2,\n",
    "            \"Adj. R-squared\": adjr2,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6bGFywMLX2R"
   },
   "source": [
    "**We are now done with pre-processing and evaluation criterion, so let's start building the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1dhWbtS_L7V"
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7VphMYlMOm1"
   },
   "outputs": [],
   "source": [
    "dtree = DecisionTreeRegressor(random_state=1)\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQAxru78MRHX"
   },
   "outputs": [],
   "source": [
    "dtree_model_train_perf = model_performance_regression(dtree, X_train, y_train)\n",
    "dtree_model_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yucD9baeMTK3"
   },
   "outputs": [],
   "source": [
    "dtree_model_val_perf = model_performance_regression(dtree, X_val, y_val)\n",
    "dtree_model_val_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYWGdJmd_L7Y"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4npJgYwMZAT"
   },
   "outputs": [],
   "source": [
    "rf_estimator = '_______'## Complete the code \n",
    "rf_estimator.fit'_______' ## Complete the code to fit the model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgThFKi0MXg9"
   },
   "outputs": [],
   "source": [
    "rf_estimator_model_train_perf = model_performance_regression(\n",
    "    rf_estimator, X_train, y_train\n",
    ")\n",
    "rf_estimator_model_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3REysfpMtYx"
   },
   "outputs": [],
   "source": [
    "rf_estimator_model_val_perf = '_______' ## Complete the code to check the performance on validation set\n",
    "rf_estimator_model_val_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d23RrA_Q_L7a"
   },
   "source": [
    "### Bagging Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkZsnc8pM_f5"
   },
   "outputs": [],
   "source": [
    "bag_estimator = '_______'## Complete the code \n",
    "bag_estimator.fit'_______' ## Complete the code to fit the model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gohTWQMRNB1P"
   },
   "outputs": [],
   "source": [
    "bag_estimator_model_train_perf = model_performance_regression(\n",
    "    bag_estimator, X_train, y_train\n",
    ")\n",
    "bag_estimator_model_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rV5iEShFNIxS"
   },
   "outputs": [],
   "source": [
    "bag_estimator_model_val_perf = '_______' ## Complete the code to check the performance on validation set\n",
    "bag_estimator_model_val_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfVq-Jai_L7c"
   },
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dujek-00NRnu"
   },
   "outputs": [],
   "source": [
    "ab_regressor = '_______'## Complete the code \n",
    "ab_regressor.fit'_______' ## Complete the code to fit the model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7uyxs0_NT63"
   },
   "outputs": [],
   "source": [
    "ab_regressor_model_train_perf = model_performance_regression(\n",
    "    ab_regressor, X_train, y_train\n",
    ")\n",
    "ab_regressor_model_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kmj_kRa6NWPT"
   },
   "outputs": [],
   "source": [
    "ab_regressor_model_val_perf = '_______' ## Complete the code to check the performance on validation set\n",
    "ab_regressor_model_val_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Mt1j1iu_L7g"
   },
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AyNHVVUxNnEC"
   },
   "outputs": [],
   "source": [
    "gb_estimator = '_______'## Complete the code \n",
    "gb_estimator.fit'_______' ## Complete the code to fit the model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKvogyh1Nk4J"
   },
   "outputs": [],
   "source": [
    "gb_estimator_model_train_perf = model_performance_regression(\n",
    "    gb_estimator, X_train, y_train\n",
    ")\n",
    "gb_estimator_model_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZPWZmuxNplb"
   },
   "outputs": [],
   "source": [
    "gb_estimator_model_val_perf = '_______' ## Complete the code to check the performance on validation set\n",
    "gb_estimator_model_val_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBKqGlAM_L7k"
   },
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_AlruhMNycE"
   },
   "outputs": [],
   "source": [
    "xgb_estimator = '_______'## Complete the code \n",
    "xgb_estimator.fit'_______' ## Complete the code to fit the model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_UydRegN0bf"
   },
   "outputs": [],
   "source": [
    "xgb_estimator_model_train_perf = model_performance_regression(\n",
    "    xgb_estimator, X_train, y_train\n",
    ")\n",
    "xgb_estimator_model_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mi-kXG9NN2S7"
   },
   "outputs": [],
   "source": [
    "xgb_estimator_model_val_perf = '_______' ## Complete the code to check the performance on validation set\n",
    "xgb_estimator_model_val_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9JNnpxa4jau"
   },
   "source": [
    "## Model performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXiMtbCPOZkH"
   },
   "outputs": [],
   "source": [
    "# training performance comparison\n",
    "\n",
    "models_train_comp_df = pd.concat(\n",
    "    [\n",
    "        dtree_model_train_perf.T,\n",
    "        rf_estimator_model_train_perf.T,\n",
    "        bag_estimator_model_train_perf.T,\n",
    "        ab_regressor_model_train_perf.T,\n",
    "        gb_estimator_model_train_perf.T,\n",
    "        xgb_estimator_model_train_perf.T,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "models_train_comp_df.columns = [\n",
    "    \"Decision tree\",\n",
    "    \"Random forest\",\n",
    "    \"Bagging Regressor\",\n",
    "    \"Adaboost\",\n",
    "    \"Gradient Boosting\",\n",
    "    \"Xgboost\",\n",
    "]\n",
    "print(\"Training performance comparison:\")\n",
    "models_train_comp_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dw-0eHpVOeSo"
   },
   "outputs": [],
   "source": [
    "# validation performance comparison\n",
    "\n",
    "'_______' ## Write the code to compare the performance on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HwEVrZJOsES"
   },
   "source": [
    "**After looking at performance of all the models, let's decide which models can further improve with hyperparameter tuning.**\n",
    "\n",
    "**Note**: You can choose to tune some other model if XGBoost gives error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cg_OREBD1NOy"
   },
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FtmPS7Ubp1D"
   },
   "source": [
    "### Tuning RandomForest Regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZv_2GlhPC_w"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "rf_tuned = RandomForestRegressor(random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {  \n",
    "                'max_depth':[4, 6, 8, 10, None],\n",
    "                'max_features': ['sqrt','log2',None],\n",
    "                'n_estimators': [80, 90, 100, 110, 120]\n",
    "}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.r2_score)\n",
    "\n",
    "# Run the grid search\n",
    "randomized_cv = RandomizedSearchCV(rf_tuned, parameters, scoring=scorer, n_iter=40, n_jobs = -1, cv=5, random_state=1)\n",
    "randomized_cv = randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "rf_tuned = randomized_cv.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "rf_tuned.fit'_______' ## Complete the code to fit the model on data\n",
    "\n",
    "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSrvh4lIPoX4"
   },
   "outputs": [],
   "source": [
    "# Creating new pipeline with best parameters\n",
    "rf_tuned = RandomForestRegressor(\n",
    "    random_state=1, max_depth=None, max_features=\"log2\", n_estimators=110\n",
    ")\n",
    "\n",
    "rf_tuned.fit'_______' ## Complete the code to fit the model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cYy0SMIiPmle"
   },
   "outputs": [],
   "source": [
    "rf_tuned_train_perf = '_______' ## Complete the code to check the performance on train set\n",
    "rf_tuned_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QD2pAgTRP2Q4"
   },
   "outputs": [],
   "source": [
    "rf_tuned_val_perf = '_______' ## Complete the code to check the performance validation set\n",
    "rf_tuned_val_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brnaQHOTLkJI"
   },
   "source": [
    "### Tuning Bagging Regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyMGEKRnQTRp"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# defining model\n",
    "Model = BaggingRegressor(random_state=1)\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = {\n",
    "              'max_samples': [0.7,0.8,0.9,1], \n",
    "              'max_features': [0.7,0.8,0.9,1],\n",
    "              'n_estimators' : [50, 100, 120, 150],\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.r2_score)\n",
    "\n",
    "#Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=20, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\n",
    "\n",
    "#Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit'_______' ## Complete the code to fit the model on data\n",
    "\n",
    "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkTs9ITSQWRT"
   },
   "outputs": [],
   "source": [
    "# Creating new pipeline with best parameters\n",
    "bag_tuned = BaggingRegressor(\n",
    "    random_state=1, max_samples=0.7, max_features=0.9, n_estimators=120\n",
    ")\n",
    "\n",
    "bag_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EA9YgsLQaMZ"
   },
   "outputs": [],
   "source": [
    "bag_tuned_train_perf = model_performance_regression(bag_tuned, X_train, y_train)\n",
    "bag_tuned_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KbUpziV7QhEB"
   },
   "outputs": [],
   "source": [
    "bag_tuned_val_perf = '_______' ## Complete the code to check the performance on validation set\n",
    "bag_tuned_val_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoLDCgw1LumE"
   },
   "source": [
    "### Tuning DecisionTree Regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a20Ib7orQpFZ"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Choose the type of classifier. \n",
    "dtree_tuned = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {'max_depth': list(np.arange(15,20)) + [None], \n",
    "              'min_samples_leaf': [1, 3] + [None],\n",
    "              'max_leaf_nodes' : [5, 10, 15] + [None],\n",
    "              'min_impurity_decrease': [0.001, 0.0]\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.r2_score)\n",
    "\n",
    "# Run the grid search\n",
    "randomized_cv = RandomizedSearchCV(dtree_tuned, parameters, scoring=scorer,cv=5, n_jobs = -1, verbose = 2, n_iter = 100)\n",
    "randomized_cv = randomized_cv.fit'_______' ## Complete the code to fit the model on data\n",
    "\n",
    "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qgWxtsyQsYq"
   },
   "outputs": [],
   "source": [
    "dtree_tuned = DecisionTreeRegressor(\n",
    "    random_state=1,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.001,\n",
    ")\n",
    "\n",
    "dtree_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tX8AJdz_Quvy"
   },
   "outputs": [],
   "source": [
    "dtree_tuned_train_perf = model_performance_regression(dtree_tuned, X_train, y_train)\n",
    "dtree_tuned_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ha1tblmxQ2X5"
   },
   "outputs": [],
   "source": [
    "dtree_tuned_val_perf = '_______' ## Complete the code to check the performance on validation set\n",
    "dtree_tuned_val_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_HT2tD3RBhx"
   },
   "source": [
    "**We have now tuned all the models, let's compare the performance of all tuned models and see which one is the best.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kERK-waMK89"
   },
   "source": [
    "## Model performance comparison and choosing the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gs09qzSYRM5r"
   },
   "outputs": [],
   "source": [
    "# training performance comparison\n",
    "\n",
    "models_train_comp_df = pd.concat(\n",
    "    [\n",
    "        dtree_tuned_train_perf.T,\n",
    "        bag_tuned_train_perf.T,\n",
    "        rf_tuned_train_perf.T,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "models_train_comp_df.columns = [\n",
    "    \"Tuned Decision Tree\",\n",
    "    \"Tuned Bagging regressor\",\n",
    "    \"Tuned Random forest\",\n",
    "]\n",
    "print(\"Training performance comparison:\")\n",
    "models_train_comp_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxieZvWDRGiI"
   },
   "outputs": [],
   "source": [
    "# validation performance comparison\n",
    "\n",
    "'_______' ## Write the code to compare the performance on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkdMW8uFRUVb"
   },
   "source": [
    "**Now we have our final model, so let's find out how our model is performing on unseen test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RuLup_zWRS_g"
   },
   "outputs": [],
   "source": [
    "# Let's check the performance on test set\n",
    "'_______' ## Write the code to check the performance of best model on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9kh16UDRcsz"
   },
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRX-io1rRhk1"
   },
   "outputs": [],
   "source": [
    "feature_names = X_train.columns\n",
    "importances = '_______' ## Complete the code to check the feature importance of the best model\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gohwGn0tbp1L"
   },
   "source": [
    "## Let's use Pipelines to build the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POEZiDwoR6it"
   },
   "outputs": [],
   "source": [
    "Model = Pipeline('_______' ) ## Complete the code to create pipeline for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcCJc9pcSA-G"
   },
   "outputs": [],
   "source": [
    "# Separating target variable and other variables\n",
    "X = df.drop(columns=\"quality\")\n",
    "Y = df[\"quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQzN_BmMSHDh"
   },
   "outputs": [],
   "source": [
    "# Splitting data into training and test set:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-NJkReMSPdm"
   },
   "outputs": [],
   "source": [
    "Model.'_______' ##  Complete the code to fit the Model obtained from above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2eCmP6u3_JS"
   },
   "outputs": [],
   "source": [
    "# Let's check the performance on test set\n",
    "Pipeline_model_test = model_performance_regression(__________, X_test, y_test) ##  Complete the code to check the performance on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdME3J172AN-"
   },
   "source": [
    "## Business Insights and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Em-julT88ACP"
   },
   "source": [
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JK2vdZwJSa0S"
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "85dWBGXv_L6k",
    "xxhpZv9y-qTw",
    "hxzULAqM2L5x",
    "KQi5ygTC-qT1",
    "qlzqMR1K-qTz",
    "xNr4bWoM-qT5",
    "Ch_TjRfF-qT5",
    "5TcqcxbK-qT3",
    "GccCfv9MbmS2",
    "DhPuzWO7hmV8",
    "MZ4AX18Z27oi",
    "0myHS43S_L7G",
    "Bp8vC9MZbp09",
    "qrxi3_UI_L7R",
    "WtM-OZGaK_9R",
    "x1dhWbtS_L7V",
    "WYWGdJmd_L7Y",
    "d23RrA_Q_L7a",
    "gfVq-Jai_L7c",
    "2Mt1j1iu_L7g",
    "gBKqGlAM_L7k",
    "D9JNnpxa4jau",
    "Cg_OREBD1NOy",
    "2FtmPS7Ubp1D",
    "brnaQHOTLkJI",
    "BoLDCgw1LumE",
    "1kERK-waMK89",
    "_9kh16UDRcsz",
    "gohwGn0tbp1L",
    "JdME3J172AN-"
   ],
   "name": "KC_Roasters_low_code_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
