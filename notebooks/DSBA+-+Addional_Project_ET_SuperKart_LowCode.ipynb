{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## SuperKart Project\n",
        "***Marks: 60***"
      ],
      "metadata": {
        "id": "9OSeW287E2kF"
      },
      "id": "9OSeW287E2kF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement"
      ],
      "metadata": {
        "id": "08wSLpHvE9Fv"
      },
      "id": "08wSLpHvE9Fv"
    },
    {
      "cell_type": "markdown",
      "id": "c0670116",
      "metadata": {
        "id": "c0670116"
      },
      "source": [
        "### Context:\n",
        "\n",
        "A sales forecast is a prediction of future sales revenue based on historical data, industry trends, and the status of the current sales pipeline. Businesses use the sales forecast to estimate weekly, monthly, quarterly, and annual sales totals. It is extremely important for a company to make an accurate sales forecast as it adds value across an organization and helps the different verticals to chalk out their future course of actions. Forecasting helps an organization to plan its sales operations by regions and provide valuable insights to the supply chain team regarding the procurement of goods and materials. \n",
        "An accurate sales forecast process has many benefits which include improved decision-making about the future and reduction of sales pipeline and forecast risks. Moreover, it helps to reduce the time spent in planning territory coverage and establish benchmarks that can be used to assess trends in the future.\n",
        "\n",
        "### Objective:\n",
        "\n",
        "SuperKart is an organization which owns a chain of supermarkets and food marts providing a wide range of products. They want to predict the future sales revenue of its different outlets so that they can strategize their sales operation across different tier cities and plan their inventory accordingly. To achieve this purpose, SuperKart has hired a data science firm, shared the sales records of its various outlets for the previous quarter and asked the firm to come up with a suitable model to predict the total sales of the stores for the upcoming quarter.\n",
        "\n",
        "\n",
        "### Data Description:\n",
        "\n",
        "The data contains the different attributes of the various products and stores.The detailed data dictionary is given below.\n",
        "\n",
        "* Product_Id - unique identifier of each product, each identifier having two letters at the beginning followed by a number.\n",
        "* Product_Weight - weight of each product\n",
        "* Product_Sugar_Content - sugar content of each product like low sugar, regular and no sugar\n",
        "* Product_Allocated_Area - ratio of the allocated display area of each product to the total display area of all the products in a store\n",
        "* Product_Type - broad category for each product like meat, snack foods, hard drinks, dairy, canned, soft drinks, health and hygiene, baking goods, bread, breakfast, frozen foods, fruits and vegetables, household, seafood, starchy foods, others\n",
        "* Product_MRP - maximum retail price of each product\n",
        "* Store_Id - unique identifier of each store\n",
        "* Store_Establishment_Year - year in which the store was established\n",
        "* Store_Size - size of the store depending on sq. feet like high, medium and low\n",
        "* Store_Location_City_Type - type of city in which the store is located like Tier 1, Tier 2 and Tier 3. Tier 1 consists of cities where the standard of living is comparatively higher than its Tier 2 and Tier 3 counterparts.\n",
        "* Store_Type - type of store depending on the products that are being sold there like Departmental Store, Supermarket Type 1, Supermarket Type 2 and Food Mart\n",
        "* Product_Store_Sales_Total - total revenue generated by the sale of that particular product in that particular store\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "609a7d83",
      "metadata": {
        "id": "609a7d83"
      },
      "source": [
        "### **Please read the instructions carefully before starting the project.** \n",
        "This is a commented Jupyter IPython Notebook file in which all the instructions and tasks to be performed are mentioned. \n",
        "* Blanks '_______' are provided in the notebook that \n",
        "needs to be filled with an appropriate code to get the correct result. With every '_______' blank, there is a comment that briefly describes what needs to be filled in the blank space. \n",
        "* Identify the task to be performed correctly, and only then proceed to write the required code.\n",
        "* Fill the code wherever asked by the commented lines like \"# write your code here\" or \"# complete the code\". Running incomplete code may throw error.\n",
        "* Please run the codes in a sequential manner from the beginning to avoid any unnecessary errors.\n",
        "* Add the results/observations (wherever mentioned) derived from the analysis in the presentation and submit the same."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing necessary libraries"
      ],
      "metadata": {
        "id": "jCsnQe8AFL25"
      },
      "id": "jCsnQe8AFL25"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0022e4d",
      "metadata": {
        "id": "c0022e4d"
      },
      "outputs": [],
      "source": [
        "# this will help in making the Python code more structured automatically (good coding practice)\n",
        "%load_ext nb_black\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Libraries to help with reading and manipulating data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Library to split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# libaries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Removes the limit for the number of displayed columns\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "# Sets the limit for the number of displayed rows\n",
        "pd.set_option(\"display.max_rows\", 100)\n",
        "\n",
        "\n",
        "# Libraries different ensemble classifiers\n",
        "from sklearn.ensemble import (\n",
        "    BaggingRegressor,\n",
        "    RandomForestRegressor,\n",
        "    AdaBoostRegressor,\n",
        "    GradientBoostingRegressor,\n",
        "    StackingRegressor,\n",
        ")\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Libraries to get different metric scores\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        ")\n",
        "\n",
        "# To tune different models\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51b91836",
      "metadata": {
        "id": "51b91836"
      },
      "source": [
        "## Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db0d776a",
      "metadata": {
        "id": "db0d776a"
      },
      "outputs": [],
      "source": [
        "kart = pd.\"_______\" # Fill the blanks to read data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a41759a",
      "metadata": {
        "id": "3a41759a"
      },
      "outputs": [],
      "source": [
        "# copying data to another variable to avoid any changes to original data\n",
        "data = kart.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview of the Dataset"
      ],
      "metadata": {
        "id": "VNkgRumsFUzz"
      },
      "id": "VNkgRumsFUzz"
    },
    {
      "cell_type": "markdown",
      "id": "65c8c14d",
      "metadata": {
        "id": "65c8c14d"
      },
      "source": [
        "### View the first and last 5 rows of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27d5a6d3",
      "metadata": {
        "id": "27d5a6d3"
      },
      "outputs": [],
      "source": [
        "data.('_______') ##  Complete the code to view top 5 rows of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb5ec8ca",
      "metadata": {
        "id": "cb5ec8ca"
      },
      "outputs": [],
      "source": [
        "data.('_______') ##  Complete the code to view last 5 rows of the data  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee04adcd",
      "metadata": {
        "id": "ee04adcd"
      },
      "source": [
        "### Understand the shape of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9040b24",
      "metadata": {
        "id": "e9040b24"
      },
      "outputs": [],
      "source": [
        "data.('_______') ##  Complete the code to view dimensions of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e25abfe4",
      "metadata": {
        "id": "e25abfe4"
      },
      "source": [
        "### Check the data types of the columns for the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e8cc237",
      "metadata": {
        "id": "0e8cc237",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "data.\"_______\" # Fill the blank to display data informaton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf1d6de3",
      "metadata": {
        "id": "cf1d6de3"
      },
      "outputs": [],
      "source": [
        "# checking for missing values in the data\n",
        "data.\"_______\".sum()  # Fill the blank to get number of missing values in data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "489451d2",
      "metadata": {
        "id": "489451d2"
      },
      "outputs": [],
      "source": [
        "# checking for duplicate values\n",
        "data.\"_______\".sum() # Fill the blank to check duplicates "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e76c12a",
      "metadata": {
        "id": "9e76c12a"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4ab23ef",
      "metadata": {
        "id": "f4ab23ef"
      },
      "source": [
        "#### Let's check the statistical summary of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae93b01c",
      "metadata": {
        "id": "ae93b01c"
      },
      "outputs": [],
      "source": [
        "data.('_______') ##  Complete the code to print the statistical summary of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12651542",
      "metadata": {
        "id": "12651542"
      },
      "source": [
        "#### Let's check the count of each unique category in each of the categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75b8c38d",
      "metadata": {
        "id": "75b8c38d"
      },
      "outputs": [],
      "source": [
        "# Making a list of all catrgorical variables\n",
        "cat_col = list(data.select_dtypes(\"object\").columns)\n",
        "\n",
        "# Printing number of count of each unique value in each column\n",
        "for column in cat_col:\n",
        "    print(data[column].value_counts())\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22d9e30",
      "metadata": {
        "id": "f22d9e30"
      },
      "outputs": [],
      "source": [
        "# Replacing reg with Regular\n",
        "data.Product_Sugar_Content.replace(to_replace=[\"reg\"], value=[\"Regular\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9468d673",
      "metadata": {
        "id": "9468d673"
      },
      "outputs": [],
      "source": [
        "data.Product_Sugar_Content.\"_________\" # Fill the blank to count values for each class in Product_Sugar_Content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43bf839c",
      "metadata": {
        "id": "43bf839c"
      },
      "outputs": [],
      "source": [
        "## extracting the first two characters from the Product_Id column and storing it in another column\n",
        "data[\"Product_Id_char\"] = data[\"Product_Id\"].str[:2]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ea2400",
      "metadata": {
        "id": "88ea2400"
      },
      "outputs": [],
      "source": [
        "data[\"Product_Id_char\"].\"________\" # Fill the blank to get all unique elements in Product_Id_char"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4af41bb0",
      "metadata": {
        "id": "4af41bb0"
      },
      "outputs": [],
      "source": [
        "data.loc[data.Product_Id_char == \"FD\", \"Product_Type\"].\"__________\"# Fill the blank to get all unique elements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "745dd04a",
      "metadata": {
        "id": "745dd04a"
      },
      "outputs": [],
      "source": [
        "data.loc[data.Product_Id_char == \"DR\", \"Product_Type\"].\"__________\" # Fill the blank to get all unique elements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55aac458",
      "metadata": {
        "id": "55aac458"
      },
      "outputs": [],
      "source": [
        "data.loc[data.Product_Id_char == \"NC\", \"Product_Type\"].\"__________\"# Fill the blank to get all unique elements"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51a4fb9b",
      "metadata": {
        "id": "51a4fb9b"
      },
      "source": [
        "#### The Product_Id column will not add any value to our analysis so let's drop it before we move forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c64abe2e",
      "metadata": {
        "id": "c64abe2e"
      },
      "outputs": [],
      "source": [
        "## dropping the column\n",
        "data = data.drop(\"________\") # Fill the blank to drop the Product_Id column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ba93318",
      "metadata": {
        "id": "3ba93318"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21341d2b",
      "metadata": {
        "id": "21341d2b"
      },
      "source": [
        "### Univariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1ebcb3d",
      "metadata": {
        "id": "c1ebcb3d"
      },
      "outputs": [],
      "source": [
        "def histogram_boxplot(data, feature, figsize=(15, 10), kde=False, bins=None):\n",
        "    \"\"\"\n",
        "    Boxplot and histogram combined\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    figsize: size of figure (default (15,10))\n",
        "    kde: whether to show the density curve (default False)\n",
        "    bins: number of bins for histogram (default None)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
        "        nrows=2,  # Number of rows of the subplot grid= 2\n",
        "        sharex=True,  # x-axis will be shared among all subplots\n",
        "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
        "        figsize=figsize,\n",
        "    )  # creating the 2 subplots\n",
        "    sns.boxplot(\n",
        "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
        "    )  # boxplot will be created and a triangle will indicate the mean value of the column\n",
        "    sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins\n",
        "    ) if bins else sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
        "    )  # For histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
        "    )  # Add mean to the histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
        "    )  # Add median to the histogram"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afe06238",
      "metadata": {
        "id": "afe06238"
      },
      "source": [
        "#### Product_Weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbc43098",
      "metadata": {
        "id": "dbc43098"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(data, \"Product_Weight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a23bdd73",
      "metadata": {
        "id": "a23bdd73"
      },
      "source": [
        "#### Product_Allocated_Area"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71792a43",
      "metadata": {
        "id": "71792a43"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(\"_______\") # Fill the blank to display plots for Product_Allocated_Area"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3242fb5",
      "metadata": {
        "id": "a3242fb5"
      },
      "source": [
        "#### Product_MRP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c401dde",
      "metadata": {
        "id": "4c401dde"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(\"_______\") # Fill the blank to display plots for Product_MRP"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a53e9ac",
      "metadata": {
        "id": "2a53e9ac"
      },
      "source": [
        "#### Product_Store_Sales_Total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cee157d",
      "metadata": {
        "id": "1cee157d"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(\"_______\") # Fill the blank to display plots for Product_Store_Sales_Total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a1f7bdd",
      "metadata": {
        "id": "1a1f7bdd"
      },
      "outputs": [],
      "source": [
        "# function to create labeled barplots\n",
        "\n",
        "\n",
        "def labeled_barplot(data, feature, perc=False, n=None):\n",
        "    \"\"\"\n",
        "    Barplot with percentage at the top\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    perc: whether to display percentages instead of count (default is False)\n",
        "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
        "    \"\"\"\n",
        "\n",
        "    total = len(data[feature])  # length of the column\n",
        "    count = data[feature].nunique()\n",
        "    if n is None:\n",
        "        plt.figure(figsize=(count + 2, 6))\n",
        "    else:\n",
        "        plt.figure(figsize=(n + 2, 6))\n",
        "\n",
        "    plt.xticks(rotation=90, fontsize=15)\n",
        "    ax = sns.countplot(\n",
        "        data=data,\n",
        "        x=feature,\n",
        "        palette=\"Paired\",\n",
        "        order=data[feature].value_counts().index[:n],\n",
        "    )\n",
        "\n",
        "    for p in ax.patches:\n",
        "        if perc == True:\n",
        "            label = \"{:.1f}%\".format(\n",
        "                100 * p.get_height() / total\n",
        "            )  # percentage of each class of the category\n",
        "        else:\n",
        "            label = p.get_height()  # count of each level of the category\n",
        "\n",
        "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
        "        y = p.get_height()  # height of the plot\n",
        "\n",
        "        ax.annotate(\n",
        "            label,\n",
        "            (x, y),\n",
        "            ha=\"center\",\n",
        "            va=\"center\",\n",
        "            size=12,\n",
        "            xytext=(0, 5),\n",
        "            textcoords=\"offset points\",\n",
        "        )  # annotate the percentage\n",
        "\n",
        "    plt.show()  # show the plot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af2e3e97",
      "metadata": {
        "id": "af2e3e97"
      },
      "source": [
        "#### Product_Sugar_Content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f4128d2",
      "metadata": {
        "id": "1f4128d2"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(data, \"Product_Sugar_Content\", perc=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65a65843",
      "metadata": {
        "id": "65a65843"
      },
      "source": [
        "#### Product_Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd5c9fc6",
      "metadata": {
        "id": "bd5c9fc6"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(\"_________\") # Fill the blank to plot barplot for Product_Type"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da06e6d9",
      "metadata": {
        "id": "da06e6d9"
      },
      "source": [
        "#### Store_Id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bb68360",
      "metadata": {
        "id": "6bb68360"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(\"_________\") # Fill the blank to plot barplot for Store_Id"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a20880d",
      "metadata": {
        "id": "6a20880d"
      },
      "source": [
        "#### Store_Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d335d873",
      "metadata": {
        "id": "d335d873"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(\"_________\") # Fill the blank to plot barplot for Store_Size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "971f7446",
      "metadata": {
        "id": "971f7446"
      },
      "source": [
        "#### Store_Location_City_Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59dacd5d",
      "metadata": {
        "id": "59dacd5d"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(\"_________\") # Fill the blank to plot barplot for Store_Location_City_Type"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9475b863",
      "metadata": {
        "id": "9475b863"
      },
      "source": [
        "#### Store_Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e53299bb",
      "metadata": {
        "id": "e53299bb"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(\"_________\") # Fill the blank to plot barplot for Store_Type"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46f0b9af",
      "metadata": {
        "id": "46f0b9af"
      },
      "source": [
        "### Bivariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "896fd22b",
      "metadata": {
        "id": "896fd22b"
      },
      "outputs": [],
      "source": [
        "cols_list = data.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.heatmap(\n",
        "    data[cols_list].corr(), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\"\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02b68b47",
      "metadata": {
        "id": "02b68b47"
      },
      "source": [
        "#### Let's check the distribution of our target variable i.e Product_Store_Sales_Total with the numeric columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12daa38c",
      "metadata": {
        "id": "12daa38c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[8, 6])\n",
        "sns.scatterplot(x=data.Product_Weight, y=data.Product_Store_Sales_Total)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06153b97",
      "metadata": {
        "id": "06153b97"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[8, 6])\n",
        "sns.scatterplot(\"________\") # Fill the blank to plot scatter plot of Product_Allocated_Area against Product_Store_Sales_Total \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aa62580",
      "metadata": {
        "id": "3aa62580"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[8, 6])\n",
        "sns.scatterplot(\"_______\") # Fill the blank to plot scatter plot of Product_MRP against Product_Store_Sales_Total \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9292a578",
      "metadata": {
        "id": "9292a578"
      },
      "source": [
        "#### Let us see from which product type the company is generating most of the revenue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca6cdaaa",
      "metadata": {
        "id": "ca6cdaaa"
      },
      "outputs": [],
      "source": [
        "df_revenue1 = data.groupby([\"Product_Type\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "plt.figure(figsize=[14, 8])\n",
        "plt.xticks(rotation=90)\n",
        "a = sns.barplot(x=df_revenue1.Product_Type, y=df_revenue1.Product_Store_Sales_Total)\n",
        "a.set_xlabel(\"Product Types\")\n",
        "a.set_ylabel(\"Revenue\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c9f4b5f",
      "metadata": {
        "id": "1c9f4b5f"
      },
      "outputs": [],
      "source": [
        "df_revenue2 = data.groupby([\"Product_Sugar_Content\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.xticks(rotation=90)\n",
        "b = sns.barplot(\"___________\") # Fill the blank to plot bar plot with Product_Sugar_content as x and Product_Store_Sales_Total as y  \n",
        "b.set_xlabel(\"Product_Sugar_content\")\n",
        "b.set_ylabel(\"Revenue\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7301694d",
      "metadata": {
        "id": "7301694d"
      },
      "source": [
        "#### Let us see from which type of stores and locations the revenue generation is more"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "090b043f",
      "metadata": {
        "id": "090b043f"
      },
      "outputs": [],
      "source": [
        "df_store_revenue = data.groupby([\"Store_Id\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.xticks(rotation=90)\n",
        "r = sns.barplot(\"________\") # Fill the blank to plot bar plot with Store_Id as x and Product_Store_Sales_Total as y  \n",
        "r.set_xlabel(\"Stores\")\n",
        "r.set_ylabel(\"Revenue\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9b5b592",
      "metadata": {
        "id": "c9b5b592"
      },
      "outputs": [],
      "source": [
        "df_revenue3 = data.groupby([\"Store_Size\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.xticks(rotation=90)\n",
        "c = sns.barplot(\"_______\") # Fill the blank to plot bar plot with Store_Size as x and Product_Store_Sales_Total as y\n",
        "c.set_xlabel(\"Store_Size\")\n",
        "c.set_ylabel(\"Revenue\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c3f0288",
      "metadata": {
        "id": "3c3f0288"
      },
      "outputs": [],
      "source": [
        "df_revenue4 = data.groupby([\"Store_Location_City_Type\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.xticks(rotation=90)\n",
        "d = sns.barplot(\"______\") # Fill the blank to plot bar plot with Store_Location_City_Type as x and Product_Store_Sales_Total as y\n",
        "d.set_xlabel(\"Store_Location_City_Type\")\n",
        "d.set_ylabel(\"Revenue\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e55ec4e1",
      "metadata": {
        "id": "e55ec4e1"
      },
      "outputs": [],
      "source": [
        "df_revenue5 = data.groupby([\"Store_Type\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.xticks(rotation=90)\n",
        "e = sns.barplot(\"_________\") # Fill the blank to plot bar plot with Store_Type as x and Product_Store_Sales_Total as y\n",
        "e.set_xlabel(\"Store_Type\")\n",
        "e.set_ylabel(\"Revenue\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8ecab60",
      "metadata": {
        "id": "e8ecab60"
      },
      "source": [
        "#### Let's check the distribution of our target variable i.e Product_Store_Sales_Total with the other categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70fccb54",
      "metadata": {
        "id": "70fccb54"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[14, 8])\n",
        "sns.boxplot(data.Store_Id, data.Product_Store_Sales_Total)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Boxplot - Store_Id Vs Product_Store_Sales_Total\")\n",
        "plt.xlabel(\"Stores\")\n",
        "plt.ylabel(\"Product_Store_Sales_Total (of each product)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "806d977c",
      "metadata": {
        "id": "806d977c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[14, 8])\n",
        "sns.boxplot(\"________\") # Fill the blank to plot boxplot of Store size against Product_Store_Sales_Total \n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Boxplot - Store_Size Vs Product_Store_Sales_Total\")\n",
        "plt.xlabel(\"Store_Size\")\n",
        "plt.ylabel(\"Product_Store_Sales_Total (of each product)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02523ef7",
      "metadata": {
        "id": "02523ef7"
      },
      "source": [
        "#### Let's now try to find out some relationship between the other columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d415aff8",
      "metadata": {
        "id": "d415aff8"
      },
      "source": [
        "#### Generally certain product types will have higher product weight than others. Let's have a look"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f79b3e0d",
      "metadata": {
        "id": "f79b3e0d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[14, 8])\n",
        "sns.boxplot(\"_________\") # Fill the blank to plot boxplot of Product_Type against Product_Weight \n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Boxplot - Product_Type Vs Product_Weight\")\n",
        "plt.xlabel(\"Types of Products\")\n",
        "plt.ylabel(\"Product_Weight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d6b86b0",
      "metadata": {
        "id": "9d6b86b0"
      },
      "source": [
        "#### Let's find out whether there is some relationship between the weight of the product and its sugar content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34df8ae3",
      "metadata": {
        "id": "34df8ae3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[14, 8])\n",
        "sns.boxplot(\"________\") # Fill the blank to plot a box plot of Product_Sugar_Content against Product_Weight \n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Boxplot - Product_Sugar_Content Vs Product_Weight\")\n",
        "plt.xlabel(\"Product_Sugar_Content\")\n",
        "plt.ylabel(\"Product_Weight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2bd287f",
      "metadata": {
        "id": "c2bd287f"
      },
      "source": [
        "#### Let's analyze the sugar content of different product types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e349075a",
      "metadata": {
        "id": "e349075a"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "sns.heatmap(\n",
        "    pd.crosstab(data[\"Product_Sugar_Content\"], data[\"Product_Type\"]),\n",
        "    annot=True,\n",
        "    fmt=\"g\",\n",
        "    cmap=\"viridis\",\n",
        ")\n",
        "plt.ylabel(\"Product_Sugar_Content\")\n",
        "plt.xlabel(\"Product_Type\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88533e8f",
      "metadata": {
        "id": "88533e8f"
      },
      "source": [
        "#### Let's find out how many items of each product type has been sold in each of the stores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c04a0c1e",
      "metadata": {
        "id": "c04a0c1e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "sns.heatmap(\"________\")  # Fill the blank to plot a heatmap with and Product_Type as x and Store_Ids as y\n",
        "plt.ylabel(\"Stores\")\n",
        "plt.xlabel(\"Product_Type\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f47c5e18",
      "metadata": {
        "id": "f47c5e18"
      },
      "source": [
        "#### Different product types have different prices. Let's analyze the trend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f538ae2",
      "metadata": {
        "id": "8f538ae2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[14, 8])\n",
        "sns.boxplot(\"__________\") # # Fill the blank to plot a box plot of Product_Type against Product_MRP\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Boxplot - Product_Type Vs Product_MRP\")\n",
        "plt.xlabel(\"Product_Type\")\n",
        "plt.ylabel(\"Product_MRP (of each product)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1bb6c77",
      "metadata": {
        "id": "d1bb6c77"
      },
      "source": [
        "#### Let's find out how the Product_MRP varies with the different stores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb496e1d",
      "metadata": {
        "id": "cb496e1d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[14, 8])\n",
        "sns.boxplot(\"_________\") # Fill the blank to plot a box plot of Store_Id against Product_MRP\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Boxplot - Store_Id Vs Product_MRP\")\n",
        "plt.xlabel(\"Stores\")\n",
        "plt.ylabel(\"Product_MRP (of each product)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09d79669",
      "metadata": {
        "id": "09d79669"
      },
      "source": [
        "#### Let's delve deeper and do a detailed analysis of each of the stores"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e457801",
      "metadata": {
        "id": "4e457801"
      },
      "source": [
        "#### OUT001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d67d5a44",
      "metadata": {
        "id": "d67d5a44"
      },
      "outputs": [],
      "source": [
        "data.loc[data[\"Store_Id\"] == \"OUT001\"].describe(include=\"all\").T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e57ead84",
      "metadata": {
        "id": "e57ead84"
      },
      "outputs": [],
      "source": [
        "data.loc[data[\"Store_Id\"] == \"OUT001\", \"Product_Store_Sales_Total\"].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd9ac2da",
      "metadata": {
        "id": "cd9ac2da"
      },
      "outputs": [],
      "source": [
        "df_OUT001 = (\n",
        "    data.loc[data[\"Store_Id\"] == \"OUT001\"]\n",
        "    .groupby([\"Product_Type\"], as_index=False)[\"Product_Store_Sales_Total\"]\n",
        "    .sum()\n",
        ")\n",
        "plt.figure(figsize=[14, 8])\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel(\"Product_Type\")\n",
        "plt.ylabel(\"Product_Store_Sales_Total\")\n",
        "plt.title(\"OUT001\")\n",
        "sns.barplot(x=df_OUT001.Product_Type, y=df_OUT001.Product_Store_Sales_Total)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "937e0981",
      "metadata": {
        "id": "937e0981"
      },
      "source": [
        "#### OUT002"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6537c822",
      "metadata": {
        "id": "6537c822"
      },
      "outputs": [],
      "source": [
        "data.loc[data[\"Store_Id\"] == \"OUT002\"].\"__________\" # Fill the blank to describe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5abba53",
      "metadata": {
        "id": "d5abba53"
      },
      "outputs": [],
      "source": [
        "data.loc[data[\"Store_Id\"] == \"OUT002\", \"Product_Store_Sales_Total\"].\"________\" # Fill the blank to perform summation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd2a2253",
      "metadata": {
        "id": "dd2a2253"
      },
      "outputs": [],
      "source": [
        "df_OUT002 = (\"_________\") # Fill the blank to form the required dataframe just like we have done in OUT001\n",
        "plt.figure(figsize=[14, 8])\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel(\"Product_Type\")\n",
        "plt.ylabel(\"Product_Store_Sales_Total\")\n",
        "plt.title(\"OUT002\")\n",
        "sns.barplot(\"________\") # Fill the blank to plot barplot for Product_Type against Product_Store_Sales_Total\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae5b4f72",
      "metadata": {
        "id": "ae5b4f72"
      },
      "source": [
        "#### OUT003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f3e70f8",
      "metadata": {
        "id": "5f3e70f8"
      },
      "outputs": [],
      "source": [
        "data.loc[data[\"Store_Id\"] == \"OUT003\"].\"__________\" # Fill the blank to describe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f647c1a",
      "metadata": {
        "id": "0f647c1a"
      },
      "outputs": [],
      "source": [
        "data.loc[data[\"Store_Id\"] == \"OUT003\", \"Product_Store_Sales_Total\"].\"________\" # Fill the blank to perform summation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54073d44",
      "metadata": {
        "id": "54073d44"
      },
      "outputs": [],
      "source": [
        "df_OUT003 = (\"_________\") # Fill the blank to form the required dataframe\n",
        "plt.figure(figsize=[14, 8])\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel(\"Product_Type\")\n",
        "plt.ylabel(\"Product_Store_Sales_Total\")\n",
        "plt.title(\"OUT003\")\n",
        "sns.barplot(\"________\") # Fill the blank to plot barplot for Product_Type against Product_Store_Sales_Total\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ecd021",
      "metadata": {
        "id": "b5ecd021"
      },
      "source": [
        "#### OUT004"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54aa971f",
      "metadata": {
        "id": "54aa971f"
      },
      "outputs": [],
      "source": [
        "data.loc[data[\"Store_Id\"] == \"OUT004\"].\"__________\" # Fill the blank to describe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1a60f82",
      "metadata": {
        "id": "b1a60f82"
      },
      "outputs": [],
      "source": [
        "data.loc[data[\"Store_Id\"] == \"OUT004\", \"Product_Store_Sales_Total\"].\"________\" # Fill the blank to perform summation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6d1305f",
      "metadata": {
        "id": "f6d1305f"
      },
      "outputs": [],
      "source": [
        "df_OUT004 = (\"_________\") # Fill the blank to form the required dataframe\n",
        "plt.figure(figsize=[14, 8])\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel(\"Product_Type\")\n",
        "plt.ylabel(\"Product_Store_Sales_Total\")\n",
        "plt.title(\"OUT004\")\n",
        "sns.barplot(\"________\") # Fill the blank to plot barplot for Product_Type against Product_Store_Sales_Total\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ef8562c",
      "metadata": {
        "id": "9ef8562c"
      },
      "source": [
        "#### Let's find out the revenue generated by the stores from each of the product types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7337f4f",
      "metadata": {
        "id": "f7337f4f"
      },
      "outputs": [],
      "source": [
        "df1 = data.groupby([\"Product_Type\", \"Store_Id\"], as_index=False)[\n",
        "    \"Product_Store_Sales_Total\"\n",
        "].sum()\n",
        "df1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3083f23",
      "metadata": {
        "id": "f3083f23"
      },
      "source": [
        "#### Let's find out the revenue generated by the stores from products having different levels of sugar content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0167eedf",
      "metadata": {
        "id": "0167eedf"
      },
      "outputs": [],
      "source": [
        "df2 = data.groupby(\"_________\")[\"________\"].sum() # Fill in the blanks to find the revenue generated by each store for the different sugar content level items \n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "deQJ0Zo1HNI0"
      },
      "id": "deQJ0Zo1HNI0"
    },
    {
      "cell_type": "markdown",
      "id": "03621a50",
      "metadata": {
        "id": "03621a50"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "288f871c",
      "metadata": {
        "id": "288f871c"
      },
      "source": [
        "#### A store which has been in the business for a long duration is more trustworthy than the newly established ones. On the other hand, older stores may sometimes lack infrastructure if proper attention is not given. So let us calculate the current age of the store and incorporate that in our model.(The data of the sales records was collected in 2021, so we will use 2021 as the base year to calculate the store age) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c18c2219",
      "metadata": {
        "id": "c18c2219"
      },
      "outputs": [],
      "source": [
        "# Outlet Age\n",
        "data[\"Store_Age_Years\"] = 2021 - data.\"___________\" ## Fill in the blank and use Store_Establishment_Year to extract the present store age"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27b7992e",
      "metadata": {
        "id": "27b7992e"
      },
      "source": [
        "#### We have 16 different product types in our dataset. So let us make two broad categories, perishables and non perishables, in order to reduce the number of product types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f67aec38",
      "metadata": {
        "id": "f67aec38"
      },
      "outputs": [],
      "source": [
        "perishables = [\n",
        "    \"Dairy\",\n",
        "    \"Meat\",\n",
        "    \"Fruits and Vegetables\",\n",
        "    \"Breakfast\",\n",
        "    \"Breads\",\n",
        "    \"Seafood\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdf7bc3a",
      "metadata": {
        "id": "bdf7bc3a"
      },
      "outputs": [],
      "source": [
        "def change(x):\n",
        "    if x in perishables:\n",
        "        return \"Perishables\"\n",
        "    else:\n",
        "        return \"Non Perishables\"\n",
        "\n",
        "\n",
        "data.Product_Type.apply(change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b32a2dac",
      "metadata": {
        "id": "b32a2dac"
      },
      "outputs": [],
      "source": [
        "change1 = []\n",
        "for i in range(0, len(data)):\n",
        "    if data.Product_Type[i] in perishables:\n",
        "        change1.append(\"Perishables\")\n",
        "    else:\n",
        "        change1.append(\"Non Perishables\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d524638",
      "metadata": {
        "id": "4d524638"
      },
      "outputs": [],
      "source": [
        "data[\"Product_Type_Category\"] = pd.Series(\"_______\") ## Fill in the blank and use change1 to create a new column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1e1c5ca",
      "metadata": {
        "id": "e1e1c5ca"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fef26ce9",
      "metadata": {
        "id": "fef26ce9"
      },
      "source": [
        "### Outlier Check\n",
        "\n",
        "- Let's check for outliers in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e04f7e5",
      "metadata": {
        "id": "5e04f7e5"
      },
      "outputs": [],
      "source": [
        "# outlier detection using boxplot\n",
        "numeric_columns = data.select_dtypes(include=np.number).columns.tolist()\n",
        "numeric_columns.remove(\"Store_Establishment_Year\")\n",
        "numeric_columns.remove(\"Store_Age_Years\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "for i, variable in enumerate(numeric_columns):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    plt.boxplot(data[variable], whis=1.5)\n",
        "    plt.tight_layout()\n",
        "    plt.title(variable)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation for modeling"
      ],
      "metadata": {
        "id": "8aCD45uCO0Wd"
      },
      "id": "8aCD45uCO0Wd"
    },
    {
      "cell_type": "markdown",
      "id": "70970767",
      "metadata": {
        "id": "70970767"
      },
      "source": [
        "- We want to forecast the Product_Store_Sales_Total. \n",
        "- Before we proceed to build a model, we'll have to encode categorical features and drop the unnecessary columns\n",
        "- We'll split the data into train and test to be able to evaluate the model that we build on the train data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b990d8b",
      "metadata": {
        "id": "5b990d8b"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dc255ba",
      "metadata": {
        "id": "6dc255ba"
      },
      "outputs": [],
      "source": [
        "data = data.\"_______\"([\"Product_Type\", \"Store_Id\", \"Store_Establishment_Year\"], axis=1) # Fill in the blank to drop the listed columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b429f181",
      "metadata": {
        "id": "b429f181"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17ff3352",
      "metadata": {
        "id": "17ff3352"
      },
      "outputs": [],
      "source": [
        "data = pd.get_dummies(\n",
        "    data,\n",
        "    columns=data.select_dtypes(include=[\"object\", \"category\"]).columns.tolist(),\n",
        "    drop_first=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62ff524c",
      "metadata": {
        "id": "62ff524c",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc13395b",
      "metadata": {
        "id": "dc13395b"
      },
      "outputs": [],
      "source": [
        "# Separating features and the target column\n",
        "X = data.\"________\"(\"Product_Store_Sales_Total\", axis=1) # Fill in the blank to drop the specified column\n",
        "y = data[\"Product_Store_Sales_Total\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61736fd2",
      "metadata": {
        "id": "61736fd2"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into train and test sets in 70:30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=1, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cae5ecd",
      "metadata": {
        "id": "6cae5ecd"
      },
      "outputs": [],
      "source": [
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fd3cabe",
      "metadata": {
        "id": "5fd3cabe"
      },
      "source": [
        "## Model Building - Strategy and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48cd8dd0",
      "metadata": {
        "id": "48cd8dd0"
      },
      "source": [
        "- We'll fit different models on the train data and observe their performance. \n",
        "- We'll try to improve that performance by tuning some hyperparameters available for that algorithm.\n",
        "- We'll use GridSearchCv for hyperparameter tuning and `r_2 score` to optimize the model.\n",
        "- R-square - `Coefficient of determination` is used to evaluate the performance of a regression model. It is the amount of the variation in the output dependent attribute which is predictable from the input independent variables.\n",
        "- Let's start by creating a function to get model scores, so that we don't have to use the same codes repeatedly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d107c3d3",
      "metadata": {
        "id": "d107c3d3"
      },
      "outputs": [],
      "source": [
        "# function to compute adjusted R-squared\n",
        "def adj_r2_score(predictors, targets, predictions):\n",
        "    r2 = r2_score(targets, predictions)\n",
        "    n = predictors.shape[0]\n",
        "    k = predictors.shape[1]\n",
        "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
        "\n",
        "\n",
        "# function to compute MAPE\n",
        "def mape_score(targets, predictions):\n",
        "    return np.mean(np.abs(targets - predictions) / targets) * 100\n",
        "\n",
        "\n",
        "# function to compute different metrics to check performance of a regression model\n",
        "def model_performance_regression(model, predictors, target):\n",
        "    \"\"\"\n",
        "    Function to compute different metrics to check regression model performance\n",
        "\n",
        "    model: regressor\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "\n",
        "    # predicting using the independent variables\n",
        "    pred = model.predict(predictors)\n",
        "\n",
        "    r2 = r2_score(target, pred)  # to compute R-squared\n",
        "    adjr2 = adj_r2_score(predictors, target, pred)  # to compute adjusted R-squared\n",
        "    rmse = np.sqrt(mean_squared_error(target, pred))  # to compute RMSE\n",
        "    mae = mean_absolute_error(target, pred)  # to compute MAE\n",
        "    mape = mape_score(target, pred)  # to compute MAPE\n",
        "\n",
        "    # creating a dataframe of metrics\n",
        "    df_perf = pd.DataFrame(\n",
        "        {\n",
        "            \"RMSE\": rmse,\n",
        "            \"MAE\": mae,\n",
        "            \"R-squared\": r2,\n",
        "            \"Adj. R-squared\": adjr2,\n",
        "            \"MAPE\": mape,\n",
        "        },\n",
        "        index=[0],\n",
        "    )\n",
        "\n",
        "    return df_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ce3fb2b",
      "metadata": {
        "id": "4ce3fb2b"
      },
      "outputs": [],
      "source": [
        "##  Function to calculate r2_score and RMSE on train and test data\n",
        "def get_model_score(model, flag=True):\n",
        "    \"\"\"\n",
        "    model : classifier to predict values of X\n",
        "\n",
        "    \"\"\"\n",
        "    # defining an empty list to store train and test results\n",
        "    score_list = []\n",
        "\n",
        "    pred_train = model.predict(X_train)\n",
        "    pred_test = model.predict(X_test)\n",
        "\n",
        "    train_r2 = metrics.r2_score(y_train, pred_train)\n",
        "    test_r2 = metrics.r2_score(y_test, pred_test)\n",
        "    train_rmse = np.sqrt(metrics.mean_squared_error(y_train, pred_train))\n",
        "    test_rmse = np.sqrt(metrics.mean_squared_error(y_test, pred_test))\n",
        "\n",
        "    # Adding all scores in the list\n",
        "    score_list.extend((train_r2, test_r2, train_rmse, test_rmse))\n",
        "\n",
        "    # If the flag is set to True then only the following print statements will be dispayed, the default value is True\n",
        "    if flag == True:\n",
        "        print(\"R-sqaure on training set : \", metrics.r2_score(y_train, pred_train))\n",
        "        print(\"R-square on test set : \", metrics.r2_score(y_test, pred_test))\n",
        "        print(\n",
        "            \"RMSE on training set : \",\n",
        "            np.sqrt(metrics.mean_squared_error(y_train, pred_train)),\n",
        "        )\n",
        "        print(\n",
        "            \"RMSE on test set : \",\n",
        "            np.sqrt(metrics.mean_squared_error(y_test, pred_test)),\n",
        "        )\n",
        "\n",
        "    # returning the list with train and test scores\n",
        "    return score_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c498d89d",
      "metadata": {
        "id": "c498d89d"
      },
      "source": [
        "## Decision Tree - Model Building and Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree Model"
      ],
      "metadata": {
        "id": "2fHIF5IyICBA"
      },
      "id": "2fHIF5IyICBA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1a8d0fa",
      "metadata": {
        "id": "d1a8d0fa"
      },
      "outputs": [],
      "source": [
        "dtree = DecisionTreeRegressor(random_state=1)\n",
        "dtree.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a3a4b52",
      "metadata": {
        "id": "3a3a4b52"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96109b81",
      "metadata": {
        "id": "96109b81"
      },
      "source": [
        "#### Checking model performance on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b9d822",
      "metadata": {
        "id": "44b9d822"
      },
      "outputs": [],
      "source": [
        "dtree_model_train_perf = model_performance_regression(dtree, X_train, y_train)\n",
        "dtree_model_train_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bc83ccd",
      "metadata": {
        "id": "7bc83ccd"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d7aa19f",
      "metadata": {
        "id": "6d7aa19f"
      },
      "outputs": [],
      "source": [
        "dtree_model_test_perf = model_performance_regression(\"___________________\") # Fill in the blank to get model performance on test set\n",
        "dtree_model_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37341729",
      "metadata": {
        "id": "37341729"
      },
      "source": [
        "### Hyperparameter Tuning - Decision Tree Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7781bc35",
      "metadata": {
        "id": "7781bc35"
      },
      "outputs": [],
      "source": [
        "# Choose the type of classifier.\n",
        "dtree_tuned = DecisionTreeRegressor(random_state=1)\n",
        "\n",
        "# Grid of parameters to choose from\n",
        "parameters = {\n",
        "    \"max_depth\": list(np.arange(1, 9)) + [None],\n",
        "    \"min_samples_leaf\": [1, 3, 5, 7, 10],\n",
        "    \"max_leaf_nodes\": [2, 3, 5, 10, 15] + [None],\n",
        "    \"min_impurity_decrease\": [0.001, 0.01, 0.1, 0.0],\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = metrics.make_scorer(metrics.r2_score)\n",
        "\n",
        "# Run the grid search\n",
        "grid_obj = GridSearchCV(dtree_tuned, parameters, scoring=scorer, cv=5)\n",
        "grid_obj = grid_obj.fit(X_train, y_train)\n",
        "\n",
        "# Set the clf to the best combination of parameters\n",
        "dtree_tuned = grid_obj.best_estimator_\n",
        "\n",
        "# Fit the best algorithm to the data.\n",
        "dtree_tuned.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c88356c",
      "metadata": {
        "id": "2c88356c"
      },
      "source": [
        "#### Checking model performance on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cccc3f91",
      "metadata": {
        "id": "cccc3f91"
      },
      "outputs": [],
      "source": [
        "dtree_tuned_model_train_perf = model_performance_regression(\n",
        "    dtree_tuned, X_train, y_train\n",
        ")\n",
        "dtree_tuned_model_train_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58048bb7",
      "metadata": {
        "id": "58048bb7"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9aabc27",
      "metadata": {
        "id": "a9aabc27"
      },
      "outputs": [],
      "source": [
        "dtree_tuned_model_test_perf = model_performance_regression(\"________________\") # Fill in the blank to check the tuned model performance on test data\n",
        "dtree_tuned_model_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bagging - Model Building and Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "IQcNoFmAIKoG"
      },
      "id": "IQcNoFmAIKoG"
    },
    {
      "cell_type": "markdown",
      "id": "f5be37da",
      "metadata": {
        "id": "f5be37da"
      },
      "source": [
        "### Bagging Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7db6067",
      "metadata": {
        "id": "b7db6067"
      },
      "outputs": [],
      "source": [
        "bagging_regressor = \"__________\"(random_state=1) # Fill in the blank to define bagging regressor\n",
        "bagging_regressor.fit(\"___________\") # Fill in the blank to fit the model on the train data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a795d478",
      "metadata": {
        "id": "a795d478"
      },
      "source": [
        "#### Checking model performance on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f84d865",
      "metadata": {
        "id": "4f84d865"
      },
      "outputs": [],
      "source": [
        "bagging_regressor_model_train_perf = model_performance_regression(\"____________\") # Fill in the blank to check model performance on train data\n",
        "bagging_regressor_model_train_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d6b38b8",
      "metadata": {
        "id": "7d6b38b8"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44a393b6",
      "metadata": {
        "id": "44a393b6"
      },
      "outputs": [],
      "source": [
        "bagging_regressor_model_test_perf = model_performance_regression(\"___________\") # Fill in the blank to check the model performance on test data\n",
        "bagging_regressor_model_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8791198a",
      "metadata": {
        "id": "8791198a"
      },
      "source": [
        "### Hyperparameter Tuning - Bagging Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abe1a4c9",
      "metadata": {
        "id": "abe1a4c9"
      },
      "outputs": [],
      "source": [
        "# Choose the type of regressor.\n",
        "bagging_estimator_tuned = BaggingRegressor(random_state=1)\n",
        "\n",
        "# Grid of parameters to choose from\n",
        "parameters = {\n",
        "    \"max_samples\": [0.7, 0.8, 0.9],\n",
        "    \"max_features\": [0.7, 0.8, 0.9],\n",
        "    \"n_estimators\": np.arange(90, 120, 10),\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = metrics.make_scorer(metrics.r2_score)\n",
        "\n",
        "# Run the grid search\n",
        "grid_obj = GridSearchCV(\"_____________\") # complete the code to run grid search with cv = 5\n",
        "grid_obj = grid_obj.fit(X_train, y_train)\n",
        "\n",
        "# Set the clf to the best combination of parameters\n",
        "bagging_estimator_tuned = grid_obj.best_estimator_\n",
        "\n",
        "# Fit the best algorithm to the data.\n",
        "bagging_estimator_tuned.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cfc3392",
      "metadata": {
        "id": "5cfc3392"
      },
      "source": [
        "#### Checking model performance on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70bd7917",
      "metadata": {
        "id": "70bd7917"
      },
      "outputs": [],
      "source": [
        "bagging_estimator_tuned_model_train_perf = model_performance_regression(\"___________\") # Fill in the blank to check tuned model performance on train data\n",
        "bagging_estimator_tuned_model_train_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f22573a6",
      "metadata": {
        "id": "f22573a6"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76f82ab7",
      "metadata": {
        "id": "76f82ab7"
      },
      "outputs": [],
      "source": [
        "bagging_estimator_tuned_model_test_perf = model_performance_regression(\"___________\") # Fill in the blank to check the tuned model performance on test data\n",
        "bagging_estimator_tuned_model_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "118e3496",
      "metadata": {
        "id": "118e3496"
      },
      "source": [
        "### Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6329988b",
      "metadata": {
        "id": "6329988b"
      },
      "outputs": [],
      "source": [
        "rf_estimator = \"__________\"(random_state=1) # Fill in the blank to define random forest regressor\n",
        "rf_estimator.fit(\"___________\") # Fill in the blank to fit the regressor to training data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6671af9a",
      "metadata": {
        "id": "6671af9a"
      },
      "source": [
        "#### Checking model performance on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6eeecc8",
      "metadata": {
        "id": "e6eeecc8"
      },
      "outputs": [],
      "source": [
        "rf_estimator_model_train_perf = model_performance_regression(\"____________\") # Fill in the blank to check model performance on train data\n",
        "rf_estimator_model_train_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26479ea1",
      "metadata": {
        "id": "26479ea1"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8740b2a8",
      "metadata": {
        "id": "8740b2a8"
      },
      "outputs": [],
      "source": [
        "rf_estimator_model_test_perf = model_performance_regression(\"____________\") # Fill in the blank to check model performance on test data\n",
        "rf_estimator_model_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a9e9a8c",
      "metadata": {
        "id": "6a9e9a8c"
      },
      "source": [
        "### Hyperparameter Tuning - Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ddc78d6",
      "metadata": {
        "id": "7ddc78d6"
      },
      "outputs": [],
      "source": [
        "# Choose the type of classifier.\n",
        "rf_tuned = RandomForestRegressor(random_state=1)\n",
        "\n",
        "# Grid of parameters to choose from\n",
        "parameters = {\n",
        "    \"max_depth\": [4, 6, 8, 10, None],\n",
        "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
        "    \"n_estimators\": [80, 90, 100, 110, 120],\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = metrics.make_scorer(metrics.r2_score)\n",
        "\n",
        "# Run the grid search\n",
        "grid_obj = GridSearchCV(\"_____________\") # complete the code to run grid search with cv = 5\n",
        "grid_obj = grid_obj.fit(X_train, y_train)\n",
        "\n",
        "# Set the clf to the best combination of parameters\n",
        "rf_tuned = grid_obj.best_estimator_\n",
        "\n",
        "# Fit the best algorithm to the data.\n",
        "rf_tuned.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72bad481",
      "metadata": {
        "id": "72bad481"
      },
      "source": [
        "#### Checking model performance on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb83a1a3",
      "metadata": {
        "id": "cb83a1a3"
      },
      "outputs": [],
      "source": [
        "rf_tuned_model_train_perf = model_performance_regression(\"___________\") # Fill in the blank to check tuned model performance on train data\n",
        "rf_tuned_model_train_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "634b422d",
      "metadata": {
        "id": "634b422d"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0d6dc2f",
      "metadata": {
        "id": "b0d6dc2f"
      },
      "outputs": [],
      "source": [
        "rf_tuned_model_test_perf = model_performance_regression(\"___________\") # Fill in the blank to check tuned model performance on test data\n",
        "rf_tuned_model_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "863f3d27",
      "metadata": {
        "id": "863f3d27"
      },
      "source": [
        "## Boosting - Model Building and Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4980b89",
      "metadata": {
        "id": "e4980b89"
      },
      "source": [
        "### AdaBoost Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "965ce7bb",
      "metadata": {
        "id": "965ce7bb"
      },
      "outputs": [],
      "source": [
        "ab_regressor = \"__________\"(random_state=1) # Fill in the blank to define the adaboost regressor\n",
        "ab_regressor.fit(\"___________\") # Fill in the blank to fit the regressor to training data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7863e4bc",
      "metadata": {
        "id": "7863e4bc"
      },
      "source": [
        "#### Checking model performance on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b953d4b8",
      "metadata": {
        "id": "b953d4b8"
      },
      "outputs": [],
      "source": [
        "ab_regressor_model_train_perf = model_performance_regression(\"____________\") # Fill in the blank to check model performance on train data\n",
        "ab_regressor_model_train_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "991a69b1",
      "metadata": {
        "id": "991a69b1"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f07917e",
      "metadata": {
        "id": "9f07917e"
      },
      "outputs": [],
      "source": [
        "ab_regressor_model_test_perf = model_performance_regression(\"____________\") # Fill in the blank to check model performance on test data\n",
        "ab_regressor_model_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c3e707",
      "metadata": {
        "id": "72c3e707"
      },
      "source": [
        "### Hyperparameter Tuning - AdaBoost Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5876f4cc",
      "metadata": {
        "id": "5876f4cc"
      },
      "outputs": [],
      "source": [
        "# Choose the type of classifier.\n",
        "ab_tuned = AdaBoostRegressor(random_state=1)\n",
        "\n",
        "# Grid of parameters to choose from\n",
        "parameters = {\n",
        "    \"n_estimators\": np.arange(10, 100, 10),\n",
        "    \"learning_rate\": [1, 0.1, 0.5, 0.01],\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = metrics.make_scorer(metrics.r2_score)\n",
        "\n",
        "# Run the grid search\n",
        "grid_obj = GridSearchCV(\"_____________\") # complete the code to run grid search with cv = 5\n",
        "grid_obj = grid_obj.fit(X_train, y_train)\n",
        "\n",
        "# Set the clf to the best combination of parameters\n",
        "ab_tuned = grid_obj.best_estimator_\n",
        "\n",
        "# Fit the best algorithm to the data.\n",
        "ab_tuned.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e12a0341",
      "metadata": {
        "id": "e12a0341"
      },
      "source": [
        "#### Checking model performance on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea98c334",
      "metadata": {
        "id": "ea98c334"
      },
      "outputs": [],
      "source": [
        "ab_tuned_model_train_perf = model_performance_regression(\"___________\") # Fill in the blank to check tuned model performance on train data\n",
        "ab_tuned_model_train_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "571675f8",
      "metadata": {
        "id": "571675f8"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5248f72",
      "metadata": {
        "id": "e5248f72"
      },
      "outputs": [],
      "source": [
        "ab_tuned_model_test_perf = model_performance_regression(\"___________\") # Fill in the blank to check tuned model performance on test data\n",
        "ab_tuned_model_train_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "206f5d57",
      "metadata": {
        "id": "206f5d57"
      },
      "source": [
        "### Gradient Boosting Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a87071a",
      "metadata": {
        "id": "6a87071a"
      },
      "outputs": [],
      "source": [
        "gb_estimator = \"___________\"(random_state=1) # Fill in the blank to define gradient boosting regressor \n",
        "gb_estimator.fit(\"___________\") # Fill in the blank to fit the regressor to training data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aac56e7",
      "metadata": {
        "id": "7aac56e7"
      },
      "source": [
        "#### Checking model performance on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d6f26c5",
      "metadata": {
        "id": "7d6f26c5"
      },
      "outputs": [],
      "source": [
        "gb_estimator_model_train_perf = model_performance_regression(\"____________\") # Fill in the blank to check model performance on train data\n",
        "gb_estimator_model_train_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa0fb9ba",
      "metadata": {
        "id": "aa0fb9ba"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "790e0176",
      "metadata": {
        "id": "790e0176"
      },
      "outputs": [],
      "source": [
        "gb_estimator_model_test_perf = model_performance_regression(\"____________\") # Fill in the blank to check model performance on test data\n",
        "gb_estimator_model_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed8ca1f0",
      "metadata": {
        "id": "ed8ca1f0"
      },
      "source": [
        "### Hyperparameter Tuning - Gradient Boosting Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5da7df63",
      "metadata": {
        "id": "5da7df63"
      },
      "outputs": [],
      "source": [
        "# Choose the type of classifier.\n",
        "gb_tuned = GradientBoostingRegressor(random_state=1)\n",
        "\n",
        "# Grid of parameters to choose from\n",
        "parameters = {\n",
        "    \"n_estimators\": np.arange(50, 200, 25),\n",
        "    \"subsample\": [0.7, 0.8, 0.9, 1],\n",
        "    \"max_features\": [0.7, 0.8, 0.9, 1],\n",
        "    \"max_depth\": [3, 5, 7, 10],\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = metrics.make_scorer(metrics.r2_score)\n",
        "\n",
        "# Run the grid search\n",
        "grid_obj = GridSearchCV(\"_____________\") # complete the code to run grid search with cv = 5\n",
        "grid_obj = grid_obj.fit(X_train, y_train)\n",
        "\n",
        "# Set the clf to the best combination of parameters\n",
        "gb_tuned = grid_obj.best_estimator_\n",
        "\n",
        "# Fit the best algorithm to the data.\n",
        "gb_tuned.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c4d7912",
      "metadata": {
        "id": "5c4d7912"
      },
      "source": [
        "#### Checking model performance on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f75d710",
      "metadata": {
        "id": "2f75d710"
      },
      "outputs": [],
      "source": [
        "gb_tuned_model_train_perf = model_performance_regression(\"___________\") # Fill in the blank to check tuned model performance on train data\n",
        "gb_tuned_model_train_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb89629a",
      "metadata": {
        "id": "cb89629a"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa9a0bd4",
      "metadata": {
        "id": "fa9a0bd4"
      },
      "outputs": [],
      "source": [
        "gb_tuned_model_test_perf = model_performance_regression(\"___________\") # Fill in the blank to check tuned model performance on test data\n",
        "gb_tuned_model_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffbda60a",
      "metadata": {
        "id": "ffbda60a"
      },
      "source": [
        "### XGBoost Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1ad20ba",
      "metadata": {
        "id": "a1ad20ba"
      },
      "outputs": [],
      "source": [
        "xgb_estimator = \"_________\"(random_state=1) # Fill in the blank to define the XGBoost regressor\n",
        "xgb_estimator.fit(\"___________\") # Fill in the blank to fit the regressor to training data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67b31c4c",
      "metadata": {
        "id": "67b31c4c"
      },
      "source": [
        "#### Checking model performance on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da72e1fd",
      "metadata": {
        "id": "da72e1fd"
      },
      "outputs": [],
      "source": [
        "xgb_estimator_model_train_perf = model_performance_regression(\"____________\") # Fill in the blank to check model performance on train data\n",
        "xgb_estimator_model_train_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd20f197",
      "metadata": {
        "id": "dd20f197"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "622c0ae2",
      "metadata": {
        "id": "622c0ae2"
      },
      "outputs": [],
      "source": [
        "xgb_estimator_model_test_perf = model_performance_regression(\"____________\") # Fill in the blank to check model performance on test data\n",
        "xgb_estimator_model_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aced13be",
      "metadata": {
        "id": "aced13be"
      },
      "source": [
        "### Hyperparameter Tuning - XGBoost Regressor "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a018bda",
      "metadata": {
        "id": "7a018bda"
      },
      "outputs": [],
      "source": [
        "# Choose the type of classifier.\n",
        "xgb_tuned = XGBRegressor(random_state=1)\n",
        "\n",
        "# Grid of parameters to choose from\n",
        "parameters = {\n",
        "    \"n_estimators\": [75, 100, 125, 150],\n",
        "    \"subsample\": [0.7, 0.8, 0.9, 1],\n",
        "    \"gamma\": [0, 1, 3, 5],\n",
        "    \"colsample_bytree\": [0.7, 0.8, 0.9, 1],\n",
        "    \"colsample_bylevel\": [0.7, 0.8, 0.9, 1],\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = metrics.make_scorer(metrics.r2_score)\n",
        "\n",
        "# Run the grid search\n",
        "grid_obj = GridSearchCV(\"_____________\") # complete the code to run grid search with cv = 5\n",
        "grid_obj = grid_obj.fit(X_train, y_train)\n",
        "\n",
        "# Set the clf to the best combination of parameters\n",
        "xgb_tuned = grid_obj.best_estimator_\n",
        "\n",
        "# Fit the best algorithm to the data.\n",
        "xgb_tuned.fit(X_train, y_train)\n",
        "xgb_tuned.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e10ca1",
      "metadata": {
        "id": "14e10ca1"
      },
      "source": [
        "#### Checking model performance on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cba48890",
      "metadata": {
        "id": "cba48890"
      },
      "outputs": [],
      "source": [
        "xgb_tuned_model_train_perf = model_performance_regression(\"___________\") # Fill in the blank to check tuned model performance on train data\n",
        "xgb_tuned_model_train_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "377fe3e2",
      "metadata": {
        "id": "377fe3e2"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4e80152",
      "metadata": {
        "id": "a4e80152"
      },
      "outputs": [],
      "source": [
        "xgb_tuned_model_test_perf = model_performance_regression(\"___________\") # Fill in the blank to check tuned model performance on train data\n",
        "xgb_tuned_model_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47a1c15a",
      "metadata": {
        "id": "47a1c15a"
      },
      "source": [
        "## Stacking Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "028a1a3b",
      "metadata": {
        "id": "028a1a3b"
      },
      "source": [
        "#### Now, let's build a stacking model with the tuned models - decision tree, random forest, and gradient boosting, then use XGBoost to get the final prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d286b37a",
      "metadata": {
        "id": "d286b37a"
      },
      "outputs": [],
      "source": [
        "estimators = [\n",
        "    (\"Decision Tree\", dtree_tuned),\n",
        "    (\"Random Forest\", rf_tuned),\n",
        "    (\"Gradient Boosting\", gb_tuned),\n",
        "]\n",
        "final_estimator = XGBRegressor(random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65473e0f",
      "metadata": {
        "id": "65473e0f"
      },
      "outputs": [],
      "source": [
        "stacking_estimator = StackingRegressor(\n",
        "    estimators=estimators, final_estimator=final_estimator, cv=5\n",
        ")\n",
        "stacking_estimator.fit(\"__________\") # Fill in the blank to fit the stacking estimator on the train data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06e3d096",
      "metadata": {
        "id": "06e3d096"
      },
      "source": [
        "#### Checking model performance on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3f148d6",
      "metadata": {
        "id": "e3f148d6"
      },
      "outputs": [],
      "source": [
        "stacking_estimator_model_train_perf = model_performance_regression(\"____________\") # Fill in the blank to check model performance on train data\n",
        "stacking_estimator_model_train_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68e99573",
      "metadata": {
        "id": "68e99573"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77760c2e",
      "metadata": {
        "id": "77760c2e"
      },
      "outputs": [],
      "source": [
        "stacking_estimator_model_test_perf = model_performance_regression(\"____________\") # Fill in the blank to check model performance on test data\n",
        "stacking_estimator_model_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0810287",
      "metadata": {
        "id": "b0810287"
      },
      "source": [
        "## Model Performance Comparison and Final Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a06d9858",
      "metadata": {
        "id": "a06d9858"
      },
      "outputs": [],
      "source": [
        "# training performance comparison\n",
        "\n",
        "models_train_comp_df = pd.concat(\n",
        "    [\n",
        "        dtree_model_train_perf.T,\n",
        "        dtree_tuned_model_train_perf.T,\n",
        "        bagging_regressor_model_train_perf.T,\n",
        "        bagging_estimator_tuned_model_train_perf.T,\n",
        "        rf_estimator_model_train_perf.T,\n",
        "        rf_tuned_model_train_perf.T,\n",
        "        ab_regressor_model_train_perf.T,\n",
        "        ab_tuned_model_train_perf.T,\n",
        "        gb_estimator_model_train_perf.T,\n",
        "        gb_tuned_model_train_perf.T,\n",
        "        xgb_estimator_model_train_perf.T,\n",
        "        xgb_tuned_model_train_perf.T,\n",
        "        stacking_estimator_model_train_perf.T,\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "\n",
        "models_train_comp_df.columns = [\n",
        "    \"Decision Tree\",\n",
        "    \"Decision Tree Tuned\",\n",
        "    \"Bagging Regressor\",\n",
        "    \"Bagging Regressor Tuned\",\n",
        "    \"Random Forest Estimator\",\n",
        "    \"Random Forest Tuned\",\n",
        "    \"Adaboost Regressor\",\n",
        "    \"Adaboost Tuned\",\n",
        "    \"Gradient Boost Estimator\",\n",
        "    \"Gradient Boost Tuned\",\n",
        "    \"XGB\",\n",
        "    \"XGB Tuned\",\n",
        "    \"Stacking Regressor\",\n",
        "]\n",
        "\n",
        "print(\"Training performance comparison:\")\n",
        "models_train_comp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "868c9619",
      "metadata": {
        "id": "868c9619",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# testing performance comparison\n",
        "\n",
        "'_______' ## Complete the code to check performance for test data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2925c09e",
      "metadata": {
        "id": "2925c09e"
      },
      "source": [
        "### Important features of the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b74a0002",
      "metadata": {
        "id": "b74a0002"
      },
      "outputs": [],
      "source": [
        "# importance of features in the tree building ( The importance of a feature is computed as the\n",
        "# (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance )\n",
        "\n",
        "print(\n",
        "    pd.DataFrame(\n",
        "        '____________'.feature_importances_, columns=[\"Imp\"], index=X_train.columns ## Complete the code to fill in best model object \n",
        "    ).sort_values(by=\"Imp\", ascending=False)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33b74b86",
      "metadata": {
        "id": "33b74b86"
      },
      "outputs": [],
      "source": [
        "feature_names = X_train.columns\n",
        "importances = '____________'.feature_importances_ ## Complete the code to fill in best model object\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
        "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "plt.xlabel(\"Relative Importance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4213339",
      "metadata": {
        "id": "e4213339"
      },
      "source": [
        "## Actionable Insights and Business Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- \n"
      ],
      "metadata": {
        "id": "qmmm6x0-J1pq"
      },
      "id": "qmmm6x0-J1pq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "___________________________________________________________________________"
      ],
      "metadata": {
        "id": "PIC3ToaeJ5W2"
      },
      "id": "PIC3ToaeJ5W2"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "08wSLpHvE9Fv",
        "jCsnQe8AFL25",
        "51b91836",
        "VNkgRumsFUzz",
        "65c8c14d",
        "ee04adcd",
        "e25abfe4",
        "9e76c12a",
        "f4ab23ef",
        "12651542",
        "51a4fb9b",
        "21341d2b",
        "46f0b9af",
        "deQJ0Zo1HNI0",
        "03621a50",
        "288f871c",
        "27b7992e",
        "fef26ce9",
        "8aCD45uCO0Wd",
        "5fd3cabe",
        "c498d89d",
        "2fHIF5IyICBA",
        "37341729",
        "IQcNoFmAIKoG",
        "f5be37da",
        "8791198a",
        "118e3496",
        "6671af9a",
        "26479ea1",
        "6a9e9a8c",
        "863f3d27",
        "e4980b89",
        "72c3e707",
        "206f5d57",
        "ed8ca1f0",
        "ffbda60a",
        "aced13be",
        "47a1c15a",
        "028a1a3b",
        "06e3d096",
        "68e99573",
        "b0810287",
        "2925c09e",
        "1e09d990",
        "e4213339"
      ],
      "name": "DSBA_Addional_Project_ET_SuperKart_LowCode_v1.1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}