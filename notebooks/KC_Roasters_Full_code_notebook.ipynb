{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EaJ8AGwpM-2"
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPPJ7VeM13-K"
   },
   "source": [
    "\n",
    "### Business Context\n",
    "\n",
    "Coffee roasting is the process of turning green coffee beans into brown ones. Brown coffee beans can be made in a variety of methods, which also influences the flavor of the end product. A roasting instrument is basically a convection oven. It is a mechanism of inflicting heat energy into the raw product which makes the product consumable.\n",
    "And the price of coffee is heavily influenced by the quality of the beans after roasting. As a result, the cost can be determined depending on the quality of the beans after roasting.\n",
    "\n",
    "The rising automation in the manufacturing business necessitates the automation of quality inspection of output products with minimal human intervention. Quality inspectors in businesses examine product quality after it is manufactured to ensure that it meets industry standards. \n",
    "\n",
    "Each product's quality inspection is a time-consuming manual process, and a low-quality product wastes upstream factory capacity, consumables, labor, and money. With the emerging AI trend, companies are looking to leverage machine learning-based technologies to automate material quality inspection during the manufacturing process to reduce human intervention while achieving human-level or better accuracy.\n",
    "\n",
    "\n",
    "\n",
    "### Objective\n",
    "\n",
    "A roasting corporation named \"KC Roasters\" has engaged you to predict the quality of a roasting instrument's outputs, which will be used to determine the price of coffee beans.\n",
    "The quality value ranges from 0 to 100 with 0 being the worst and 100 being the best.\n",
    "and the higher the quality of the beans, the higher the price.\n",
    "\n",
    "The coffee roasting instrument used by Roasters is divided into five equal-sized compartments, each with three temperature sensors. 3 sensors have been installed at 3 different locations to be able to capture temperature at different locations inside the chamber.\n",
    "Additionally, the height of raw material (volume entering the chamber) and relative humidity of roasted material is provided\n",
    "\n",
    "The data shared consists of 17 predictor variables and a continuous target variable, and the aim is to build a Regression model which can accurately predict the quality of the product. After finding out the quality, the company can decide the cost of beans effectively.\n",
    "\n",
    "\n",
    "### Data Dictionary\n",
    "- T_data_1_1 - Temperature recorded by 1st sensor in the 1st chamber in Fahrenheit\n",
    "- T_data_1_2 - Temperature recorded by 2nd sensor in the 1st chamber in Fahrenheit\n",
    "- T_data_1_3 - Temperature recorded by 3rd sensor in the 1st chamber in Fahrenheit\n",
    "- T_data_2_1 - Temperature recorded by 1st sensor in the 2nd chamber in Fahrenheit\n",
    "- T_data_2_2 - Temperature recorded by 2nd sensor in the 2nd chamber in Fahrenheit\n",
    "- T_data_2_3 - Temperature recorded by 3rd sensor in the 2nd chamber in Fahrenheit\n",
    "- T_data_3_1 - Temperature recorded by 1st sensor in the 3rd chamber in Fahrenheit\n",
    "- T_data_3_2 - Temperature recorded by 2nd sensor in the 3rd chamber in Fahrenheit\n",
    "- T_data_3_3 - Temperature recorded by 3rd sensor in the 3rd chamber in Fahrenheit\n",
    "- T_data_4_1 - Temperature recorded by 1st sensor in the 4th chamber in Fahrenheit\n",
    "- T_data_4_2 - Temperature recorded by 2nd sensor in the 4th chamber in Fahrenheit\n",
    "- T_data_4_3 - Temperature recorded by 3rd sensor in the 4th chamber in Fahrenheit\n",
    "- T_data_5_1 - Temperature recorded by 1st sensor in the 5th chamber in Fahrenheit\n",
    "- T_data_5_2 - Temperature recorded by 2nd sensor in the 5th chamber in Fahrenheit\n",
    "- T_data_5_3 - Temperature recorded by 3rd sensor in the 5th chamber in Fahrenheit\n",
    "- H_data - Height of Raw material layer, basically represents the volume of raw material going inside the chamber in pounds.\n",
    "- AH_data - Roasted Coffee beans relative humidity.\n",
    "- quality - Quality of the beans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85dWBGXv_L6k"
   },
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas==1.5.3 numpy==1.25.2 matplotlib==3.7.1 seaborn==0.13.1 scikit-learn==1.2.2 xgboost==2.0.3 -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: After running the above cell, kindly restart the notebook kernel and run all cells sequentially from the start again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2zc0ZktV1QT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxhpZv9y-qTw"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Us_sJA1pV5aO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBNRcBeZ_L6o"
   },
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjSWJXZPV6-v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhPuzWO7hmV8"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiUOQoPu_L6s"
   },
   "source": [
    "### Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXZecu9pUgNW"
   },
   "outputs": [],
   "source": [
    "# function to plot a boxplot and a histogram along the same scale.\n",
    "\n",
    "\n",
    "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (12,7))\n",
    "    kde: whether to the show density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows=2,  # Number of rows of the subplot grid= 2\n",
    "        sharex=True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize=figsize,\n",
    "    )  # creating the 2 subplots\n",
    "    sns.boxplot(\n",
    "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
    "    )  # boxplot will be created and a triangle will indicate the mean value of the column\n",
    "    sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
    "    ) if bins else sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
    "    )  # For histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
    "    )  # Add mean to the histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
    "    )  # Add median to the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AXITHmedFlgV"
   },
   "outputs": [],
   "source": [
    "# Observations on T_data_1_1\n",
    "histogram_boxplot(df, \"T_data_1_1\", figsize=(12, 7), kde=False, bins=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0myHS43S_L7G"
   },
   "source": [
    "### Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aps0IftY8-wI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bp8vC9MZbp09"
   },
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ac9ghzzuWSL6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtM-OZGaK_9R"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIKB264q_L7T"
   },
   "source": [
    "**Let's create a function to calculate different metrics, so that we don't have to use the same code repeatedly for each model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJe-BS-1LFG7"
   },
   "outputs": [],
   "source": [
    "# function to compute adjusted R-squared\n",
    "def adj_r2_score(predictors, targets, predictions):\n",
    "    r2 = r2_score(targets, predictions)\n",
    "    n = predictors.shape[0]\n",
    "    k = predictors.shape[1]\n",
    "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "\n",
    "# function to compute different metrics to check performance of a regression model\n",
    "def model_performance_regression(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check regression model performance\n",
    "\n",
    "    model: regressor\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "\n",
    "    # predicting using the independent variables\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    r2 = r2_score(target, pred)  # to compute R-squared\n",
    "    adjr2 = adj_r2_score(predictors, target, pred)  # to compute adjusted R-squared\n",
    "    rmse = np.sqrt(mean_squared_error(target, pred))  # to compute RMSE\n",
    "    mae = mean_absolute_error(target, pred)  # to compute MAE\n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R-squared\": r2,\n",
    "            \"Adj. R-squared\": adjr2,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6bGFywMLX2R"
   },
   "source": [
    "**We are now done with pre-processing and evaluation criterion, so let's start building the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1dhWbtS_L7V"
   },
   "source": [
    "### Sample code for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7VphMYlMOm1"
   },
   "outputs": [],
   "source": [
    "dtree = DecisionTreeRegressor(random_state=1)\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQAxru78MRHX"
   },
   "outputs": [],
   "source": [
    "dtree_model_train_perf = model_performance_regression(dtree, X_train, y_train)\n",
    "dtree_model_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yucD9baeMTK3"
   },
   "outputs": [],
   "source": [
    "dtree_model_val_perf = model_performance_regression(dtree, X_val, y_val)\n",
    "dtree_model_val_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNQj-EuwOBcJ"
   },
   "source": [
    "### Model Performance comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HwEVrZJOsES"
   },
   "source": [
    "**After looking at performance of all the models, let's decide which models can further improve with hyperparameter tuning.**\n",
    "\n",
    "**Note**: You can choose to tune some other model if XGBoost gives error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Zo1uSCvOx6Y"
   },
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfUu_K66W6Et"
   },
   "source": [
    "**Hyperparameter tuning can take a long time to run, so to avoid that time complexity - you can use the following grids, wherever required.**\n",
    "\n",
    "- For Bagging :\n",
    "\n",
    "param_grid = {\n",
    "    'max_samples': [0.7,0.8,0.9,1], \n",
    "    'max_features': [0.7,0.8,0.9,1],\n",
    "    'n_estimators' : [50, 100, 120, 150],\n",
    "}\n",
    "\n",
    "- For Random Forest:\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth':[4, 6, 8, 10, None],\n",
    "    'max_features': ['sqrt','log2',None],\n",
    "    'n_estimators': [80, 90, 100, 110, 120]\n",
    "}\n",
    "\n",
    "- For Decision Trees:\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': list(np.arange(15,20)) + [None], \n",
    "    'min_samples_leaf': [1, 3] + [None],\n",
    "    'max_leaf_nodes' : [5, 10, 15] + [None],\n",
    "    'min_impurity_decrease': [0.001, 0.0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efIZlaH8O3HF"
   },
   "source": [
    "### Sample code for tuning Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZv_2GlhPC_w"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "rf_tuned = RandomForestRegressor(random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {  \n",
    "                'max_depth':[4, 6, 8, 10, None],\n",
    "                'max_features': ['sqrt','log2',None],\n",
    "                'n_estimators': [80, 90, 100, 110, 120]\n",
    "}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.r2_score)\n",
    "\n",
    "# Run the grid search\n",
    "randomized_cv = RandomizedSearchCV(rf_tuned, parameters, scoring=scorer, n_iter=40, n_jobs = -1, cv=5, random_state=1)\n",
    "randomized_cv = randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "rf_tuned = randomized_cv.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "rf_tuned.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_HT2tD3RBhx"
   },
   "source": [
    "**We have now tuned all the models, let's compare the performance of all tuned models and see which one is the best.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-zrbQi9Q8WN"
   },
   "source": [
    "## Model performance comparison and choosing the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gAY6DMZC9chk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxQ4HLBsZgd2"
   },
   "source": [
    "### Test set final performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_0AqpvtZhwt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9kh16UDRcsz"
   },
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzzdKXtgwXsi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gohwGn0tbp1L"
   },
   "source": [
    "## Let's use Pipelines to build the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cScnwtiwYbg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdME3J172AN-"
   },
   "source": [
    "## Business Insights and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JK2vdZwJSa0S"
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "85dWBGXv_L6k",
    "xxhpZv9y-qTw",
    "qBNRcBeZ_L6o",
    "DhPuzWO7hmV8",
    "kiUOQoPu_L6s",
    "0myHS43S_L7G",
    "Bp8vC9MZbp09",
    "WtM-OZGaK_9R",
    "x1dhWbtS_L7V",
    "1Zo1uSCvOx6Y",
    "efIZlaH8O3HF",
    "U-zrbQi9Q8WN",
    "AxQ4HLBsZgd2",
    "_9kh16UDRcsz",
    "gohwGn0tbp1L",
    "JdME3J172AN-"
   ],
   "name": "KC_Roasters_Full_code_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
